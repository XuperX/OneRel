{"cells":[{"cell_type":"code","execution_count":24,"metadata":{"id":"2EhBe2Kq5zLQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708417214491,"user_tz":0,"elapsed":1928,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"7e079d89-e31b-4358-8fb5-d375bb38ca2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"G5Vte9UJ7-d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708417214828,"user_tz":0,"elapsed":341,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"af795593-e63a-461b-b328-869c17724781"},"outputs":[{"output_type":"stream","name":"stdout","text":["this is a one off code\n","check_input.py\tdata_loader.py\tinspect_input.py  oneRel_config.py  requirements.txt  utils\n","checkpoint\tdebug\t\tjobscript_colab   pre_trained_bert  result\t      venv\n","config\t\tframework\tlog\t\t  __pycache__\t    test.py\n","data\t\timg\t\tmodels\t\t  README.md\t    train.py\n","/content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel\n"]}],"source":["#%cd pre_trained_bert/\n","#!ls\n","#!git lfs install\n","#!git clone https://huggingface.co/allenai/scibert_scivocab_cased\n","!echo \"this is a one off code\"\n","#!mv scibert_scivocab_cased/* .\n","!ls\n","\n","%cd /content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udWhdc706dC_","executionInfo":{"status":"ok","timestamp":1708417239358,"user_tz":0,"elapsed":24531,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"2239da95-aaba-468b-e64f-f31f981370fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sphinxcontrib-htmlhelp==2.0.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.5)\n","Requirement already satisfied: sphinxcontrib-jsmath==1.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-qthelp==1.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.0.7)\n","Requirement already satisfied: sphinxcontrib-serializinghtml==1.1.10 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.1.10)\n","Requirement already satisfied: SQLAlchemy==2.0.24 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.0.24)\n","Requirement already satisfied: sqlglot==19.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (19.9.0)\n","Requirement already satisfied: sqlparse==0.4.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.4.4)\n","Requirement already satisfied: srsly==2.4.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.4.8)\n","Requirement already satisfied: stanio==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.3.0)\n","Requirement already satisfied: statsmodels==0.14.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.14.1)\n","Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.12)\n","Requirement already satisfied: tables==3.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.8.0)\n","Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.9.0)\n","Requirement already satisfied: tbb==2021.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (2021.11.0)\n","Requirement already satisfied: tblib==3.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.0.0)\n","Requirement already satisfied: tenacity==8.2.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (8.2.3)\n","Requirement already satisfied: tensorboard==2.15.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.15.1)\n","Requirement already satisfied: tensorboard-data-server==0.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.7.2)\n","Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (2.15.0)\n","Requirement already satisfied: tensorflow-datasets==4.9.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (4.9.4)\n","Requirement already satisfied: tensorflow-estimator==2.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.15.0)\n","Requirement already satisfied: tensorflow-gcs-config==2.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (2.15.0)\n","Requirement already satisfied: tensorflow-hub==0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (0.16.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.35.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (0.35.0)\n","Requirement already satisfied: tensorflow-metadata==1.14.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (1.14.0)\n","Requirement already satisfied: tensorflow-probability==0.22.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (0.22.0)\n","Requirement already satisfied: tensorstore==0.1.45 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (0.1.45)\n","Requirement already satisfied: termcolor==2.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (2.4.0)\n","Requirement already satisfied: terminado==0.18.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (0.18.0)\n","Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (1.3)\n","Requirement already satisfied: textblob==0.17.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.17.1)\n","Requirement already satisfied: tf-slim==1.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (1.1.0)\n","Requirement already satisfied: thinc==8.1.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (8.1.12)\n","Requirement already satisfied: threadpoolctl==3.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (3.2.0)\n","Requirement already satisfied: tifffile==2023.12.9 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (2023.12.9)\n","Requirement already satisfied: tinycss2==1.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (1.2.1)\n","Requirement already satisfied: tokenizers==0.15.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (0.15.1)\n","Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (0.10.2)\n","Requirement already satisfied: tomli==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (2.0.1)\n","Requirement already satisfied: toolz==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (0.12.1)\n","Requirement already satisfied: torch==2.1.0+cu121 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (2.1.0+cu121)\n","Requirement already satisfied: torchaudio==2.1.0+cu121 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (2.1.0+cu121)\n","Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 43)) (0.7.0)\n","Requirement already satisfied: torchsummary==1.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (1.5.1)\n","Requirement already satisfied: torchtext==0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 45)) (0.16.0)\n","Requirement already satisfied: torchvision==0.16.0+cu121 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 46)) (0.16.0+cu121)\n","Requirement already satisfied: tornado==6.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 47)) (6.3.2)\n","Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 48)) (4.66.1)\n","Requirement already satisfied: traitlets==5.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 49)) (5.7.1)\n","Requirement already satisfied: traittypes==0.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (0.2.1)\n","Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 51)) (4.35.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 52)) (2.1.0)\n","Requirement already satisfied: tweepy==4.14.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 53)) (4.14.0)\n","Requirement already satisfied: typer==0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 54)) (0.9.0)\n","Requirement already satisfied: types-pytz==2023.3.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 55)) (2023.3.1.1)\n","Requirement already satisfied: types-setuptools==69.0.0.20240125 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 56)) (69.0.0.20240125)\n","Requirement already satisfied: typing_extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 57)) (4.5.0)\n","Requirement already satisfied: tzlocal==5.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 58)) (5.2)\n","Requirement already satisfied: uc-micro-py==1.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 59)) (1.0.2)\n","Requirement already satisfied: uritemplate==4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 60)) (4.1.1)\n","Requirement already satisfied: urllib3==2.0.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 61)) (2.0.7)\n","Requirement already satisfied: vega-datasets==0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 62)) (0.9.0)\n","Requirement already satisfied: wadllib==1.3.6 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 63)) (1.3.6)\n","Requirement already satisfied: wasabi==1.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 64)) (1.1.2)\n","Requirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 65)) (0.2.13)\n","Requirement already satisfied: webcolors==1.13 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 66)) (1.13)\n","Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 67)) (0.5.1)\n","Requirement already satisfied: websocket-client==1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 68)) (1.7.0)\n","Requirement already satisfied: Werkzeug==3.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 69)) (3.0.1)\n","Requirement already satisfied: wheel==0.42.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 70)) (0.42.0)\n","Requirement already satisfied: widgetsnbextension==3.6.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 71)) (3.6.6)\n","Requirement already satisfied: wordcloud==1.9.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 72)) (1.9.3)\n","Requirement already satisfied: wrapt==1.14.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 73)) (1.14.1)\n","Requirement already satisfied: xarray==2023.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 74)) (2023.7.0)\n","Requirement already satisfied: xarray-einstats==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 75)) (0.7.0)\n","Requirement already satisfied: xgboost==2.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 76)) (2.0.3)\n","Requirement already satisfied: xlrd==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 77)) (2.0.1)\n","Requirement already satisfied: xxhash==3.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 78)) (3.4.1)\n","Requirement already satisfied: xyzservices==2023.10.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 79)) (2023.10.1)\n","Requirement already satisfied: yarl==1.9.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 80)) (1.9.4)\n","Requirement already satisfied: yellowbrick==1.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 81)) (1.5)\n","Requirement already satisfied: yfinance==0.2.36 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 82)) (0.2.36)\n","Requirement already satisfied: zict==3.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 83)) (3.0.0)\n","Requirement already satisfied: zipp==3.17.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 84)) (3.17.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==2.0.24->-r requirements.txt (line 5)) (3.0.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from srsly==2.4.8->-r requirements.txt (line 8)) (2.0.10)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanio==0.3.0->-r requirements.txt (line 9)) (1.25.2)\n","Requirement already satisfied: scipy!=1.9.2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.1->-r requirements.txt (line 10)) (1.11.4)\n","Requirement already satisfied: pandas!=2.1.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.1->-r requirements.txt (line 10)) (1.5.3)\n","Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.1->-r requirements.txt (line 10)) (0.5.6)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels==0.14.1->-r requirements.txt (line 10)) (23.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy==1.12->-r requirements.txt (line 11)) (1.3.0)\n","Requirement already satisfied: cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from tables==3.8.0->-r requirements.txt (line 12)) (3.0.8)\n","Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables==3.8.0->-r requirements.txt (line 12)) (2.9.0)\n","Requirement already satisfied: blosc2~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tables==3.8.0->-r requirements.txt (line 12)) (2.0.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from tables==3.8.0->-r requirements.txt (line 12)) (9.0.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (1.60.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (3.5.2)\n","Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.15.1->-r requirements.txt (line 17)) (1.16.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (3.3.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r requirements.txt (line 19)) (2.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.9.4->-r requirements.txt (line 20)) (8.1.7)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.9.4->-r requirements.txt (line 20)) (0.1.8)\n","Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.9.4->-r requirements.txt (line 20)) (1.6.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.9.4->-r requirements.txt (line 20)) (2.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.9.4->-r requirements.txt (line 20)) (5.9.5)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.9.4->-r requirements.txt (line 20)) (0.5.0)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata==1.14.0->-r requirements.txt (line 25)) (1.62.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.22.0->-r requirements.txt (line 26)) (4.4.2)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability==0.22.0->-r requirements.txt (line 26)) (2.2.1)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado==0.18.0->-r requirements.txt (line 29)) (0.7.0)\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob==0.17.1->-r requirements.txt (line 31)) (3.8.1)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc==8.1.12->-r requirements.txt (line 33)) (0.7.11)\n","Requirement already satisfied: murmurhash<1.1.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from thinc==8.1.12->-r requirements.txt (line 33)) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from thinc==8.1.12->-r requirements.txt (line 33)) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from thinc==8.1.12->-r requirements.txt (line 33)) (3.0.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc==8.1.12->-r requirements.txt (line 33)) (0.1.4)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from thinc==8.1.12->-r requirements.txt (line 33)) (1.10.14)\n","Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers==0.15.1->-r requirements.txt (line 37)) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121->-r requirements.txt (line 41)) (3.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121->-r requirements.txt (line 41)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121->-r requirements.txt (line 41)) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu121->-r requirements.txt (line 41)) (2023.6.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121->-r requirements.txt (line 46)) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->-r requirements.txt (line 51)) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->-r requirements.txt (line 51)) (2023.12.25)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->-r requirements.txt (line 51)) (0.4.2)\n","Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy==4.14.0->-r requirements.txt (line 53)) (3.2.2)\n","Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy==4.14.0->-r requirements.txt (line 53)) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug==3.0.1->-r requirements.txt (line 69)) (2.1.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (6.5.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud==1.9.3->-r requirements.txt (line 72)) (3.7.1)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl==1.9.4->-r requirements.txt (line 80)) (3.6)\n","Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl==1.9.4->-r requirements.txt (line 80)) (6.0.5)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick==1.5->-r requirements.txt (line 81)) (1.2.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick==1.5->-r requirements.txt (line 81)) (0.12.1)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance==0.2.36->-r requirements.txt (line 82)) (0.0.11)\n","Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance==0.2.36->-r requirements.txt (line 82)) (4.9.4)\n","Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance==0.2.36->-r requirements.txt (line 82)) (1.4.4)\n","Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance==0.2.36->-r requirements.txt (line 82)) (2023.4)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance==0.2.36->-r requirements.txt (line 82)) (2.4.0)\n","Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance==0.2.36->-r requirements.txt (line 82)) (3.17.1)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance==0.2.36->-r requirements.txt (line 82)) (4.12.3)\n","Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance==0.2.36->-r requirements.txt (line 82)) (1.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.36->-r requirements.txt (line 82)) (2.5)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from blosc2~=2.0.0->tables==3.8.0->-r requirements.txt (line 12)) (1.0.7)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets==4.9.4->-r requirements.txt (line 20)) (6.1.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.15.1->-r requirements.txt (line 17)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.15.1->-r requirements.txt (line 17)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.15.1->-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud==1.9.3->-r requirements.txt (line 72)) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud==1.9.3->-r requirements.txt (line 72)) (4.48.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud==1.9.3->-r requirements.txt (line 72)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud==1.9.3->-r requirements.txt (line 72)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud==1.9.3->-r requirements.txt (line 72)) (2.8.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob==0.17.1->-r requirements.txt (line 31)) (1.3.2)\n","Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (23.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (23.1.0)\n","Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (5.7.1)\n","Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (6.1.12)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.2.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (5.9.2)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (6.5.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (1.6.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (5.5.6)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (1.8.2)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.19.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (1.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.15.1->-r requirements.txt (line 17)) (3.3.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.15.1->-r requirements.txt (line 17)) (2024.2.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (4.2.0)\n","Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (1.24.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.2.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.4)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.3.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.9.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (1.5.1)\n","Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (2.16.1)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (2.19.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (4.19.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.15.1->-r requirements.txt (line 17)) (0.5.1)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (21.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (7.34.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.19.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (3.0.43)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (4.9.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.33.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.17.1)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (3.7.1)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (1.16.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (1.2.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (2.21)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook>=4.4.1->widgetsnbextension==3.6.6->-r requirements.txt (line 71)) (0.8.3)\n","Requirement already satisfied: keras-bert in /usr/local/lib/python3.10/dist-packages (0.89.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-bert) (1.25.2)\n","Requirement already satisfied: keras-transformer==0.40.0 in /usr/local/lib/python3.10/dist-packages (from keras-bert) (0.40.0)\n","Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert) (0.13.0)\n","Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert) (0.29.0)\n","Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert) (0.16.0)\n","Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert) (0.8.0)\n","Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.10/dist-packages (from keras-transformer==0.40.0->keras-bert) (0.10.0)\n","Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.10/dist-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert) (0.51.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: print_color in /usr/local/lib/python3.10/dist-packages (0.4.6)\n"]}],"source":["\n","!pip install -r requirements.txt\n","!pip install keras-bert\n","!pip install sentencepiece\n","!pip install print_color"]},{"cell_type":"code","source":[],"metadata":{"id":"eEEBUHV-TvFO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":33,"metadata":{"id":"BdhYNQUX7xw-","executionInfo":{"status":"ok","timestamp":1708422383747,"user_tz":0,"elapsed":3492345,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"179ddaf3-ee3a-4257-ad57-bfc3908869bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-20 08:48:13.784733: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-20 08:48:13.784789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-20 08:48:13.786149: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-20 08:48:13.793664: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-20 08:48:14.830381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12020, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n","  warnings.warn(\n","2024-02-20 08:48:19.808158: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.815389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.815600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.816234: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.816426: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.816572: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.918932: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.919132: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.919266: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2024-02-20 08:48:19.919317: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:48:19.919453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Initialized bert_model_dir: None\n","Using bert_model_dir: None\n","make sure you have modified the model and model path in models/rel_model.py\n","loading configuration file ./pre_trained_bert/scibert_scivocab_cased/config.json\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31116\n","}\n","\n","loading weights file ./pre_trained_bert/scibert_scivocab_cased/pytorch_model.bin\n","Some weights of the model checkpoint at ./pre_trained_bert/scibert_scivocab_cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertModel were initialized from the model checkpoint at ./pre_trained_bert/scibert_scivocab_cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","\u001b[31m(array([  101,   186,     1, 11417,     1,   125,     1,  8848,     1,\n","         501,     1,   136,     1,  3784,     1,  6388,     1,   253,\n","           1,  2763,     1,  2212,     1,  1181, 30123, 30168,  3468,\n","           1,  8553,     1,   124,     1,   226, 30121,     1,  2534,\n","       30124,     1,  1745,     1,  9443,     1,   202,     1, 19121,\n","           1,   146,     1,   547,     1,  1086,     1,  8278,     1,\n","         272,     1,  7654, 30177, 27118,     1,   111,     1,  1626,\n","           1,   977,     1,  1005,     1,   125,     1,  1082,     1,\n","        9443,     1,   193,     1,   111,     1,   977,     1,   987,\n","           1,   125,     1,   306,     1,  1086, 30121,     1,   102]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1]), array([[1., 1., 1., ..., 1., 1., 1.],\n","       [1., 1., 1., ..., 1., 1., 1.],\n","       [1., 1., 1., ..., 1., 1., 1.],\n","       ...,\n","       [1., 1., 1., ..., 1., 1., 1.],\n","       [1., 1., 1., ..., 1., 1., 1.],\n","       [1., 1., 1., ..., 1., 1., 1.]]), 90, array([[[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       ...,\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]]]), [['background correction', '/Operation/hasMeans/Means', 'affy'], ['raw data', '/Data/inputOf/Operation', 'normalization'], ['normalization', '/Operation/hasMeans/Means', 'affy']], ['[CLS]', 'The', '[unused1]', 'normalization', '[unused1]', 'of', '[unused1]', 'raw', '[unused1]', 'data', '[unused1]', 'and', '[unused1]', 'background', '[unused1]', 'correction', '[unused1]', 'was', '[unused1]', 'conducted', '[unused1]', 'via', '[unused1]', 'aff', '##y', '##[', '##9]', '[unused1]', 'package', '[unused1]', 'in', '[unused1]', 'R', '##.', '[unused1]', 'Moreover', '##,', '[unused1]', 'multiple', '[unused1]', 'probes', '[unused1]', 'that', '[unused1]', 'corresponded', '[unused1]', 'to', '[unused1]', 'one', '[unused1]', 'gene', '[unused1]', 'symbol', '[unused1]', 'were', '[unused1]', 'summarized', '##', '##taking', '[unused1]', 'the', '[unused1]', 'average', '[unused1]', 'expression', '[unused1]', 'values', '[unused1]', 'of', '[unused1]', 'those', '[unused1]', 'probes', '[unused1]', 'as', '[unused1]', 'the', '[unused1]', 'expression', '[unused1]', 'value', '[unused1]', 'of', '[unused1]', 'this', '[unused1]', 'gene', '##.', '[unused1]', '[SEP]'])\u001b[0m\n","\u001b[31m(array([  101,   499,     1,   510,     1,   111,     1, 18859, 24785,\n","         647,     1,  3557,     1,  1867,  1633,  3316, 30121, 13584,\n","       24785,   647, 30121,  1500, 30165, 17044, 30165, 12828, 30121,\n","       30163,  2393,     1,   146,     1,  6555,     1,   105,     1,\n","        6254, 30134,  7299,     1,   125,     1,   111,     1,   681,\n","           1,   125,     1,   889,     1,  5256,     1,  1086,     1,\n","         977,     1,   124,     1,  1407,     1,  7498,     1,  2107,\n","           1,   188,     1,   202,     1,   125,     1,  8227,     1,\n","        7498,     1,  2225,     1,  2107,     1,  9199,     1,   102]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 81, array([[[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       ...,\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]]]), [['the number of studies', '/Data/inputOf/Operation', 'meta-analysis']], ['[CLS]', 'We', '[unused1]', 'used', '[unused1]', 'the', '[unused1]', 'Onc', '##omi', '##ne', '[unused1]', 'database', '[unused1]', 'http', '##://', '##www', '##.', '##onc', '##omi', '##ne', '##.', '##org', '##/', '##main', '##/', '##index', '##.', '##j', '##sp', '[unused1]', 'to', '[unused1]', 'conduct', '[unused1]', 'a', '[unused1]', 'meta', '##-', '##analysis', '[unused1]', 'of', '[unused1]', 'the', '[unused1]', 'number', '[unused1]', 'of', '[unused1]', 'studies', '[unused1]', 'comparing', '[unused1]', 'gene', '[unused1]', 'expression', '[unused1]', 'in', '[unused1]', 'normal', '[unused1]', 'prostate', '[unused1]', 'tissue', '[unused1]', 'with', '[unused1]', 'that', '[unused1]', 'of', '[unused1]', 'localized', '[unused1]', 'prostate', '[unused1]', 'tumor', '[unused1]', 'tissue', '[unused1]', '[12].', '[unused1]', '[SEP]'])\u001b[0m\n","total time 8.876089572906494\n","total time 1.4985365867614746\n","total time 0.25990796089172363\n","total time 3.0453388690948486\n","epoch:   4, step:  100, speed: 170.02ms/b, train loss: 4.331\n","total time 3.3622779846191406\n","total time 3.3813929557800293\n","total time 9.517282247543335\n","epoch:   7, step:  200, speed: 157.90ms/b, train loss: 0.174\n","total time 8.950820207595825\n","total time 5.332467555999756\n","epoch:   9, step:  300, speed: 163.14ms/b, train loss: 0.057\n","total time 12.261505126953125\n","total time 2.6954948902130127\n","epoch:  11, step:  400, speed: 160.24ms/b, train loss: 0.032\n","total time 6.665024042129517\n","total time 1.8105168342590332\n","total time 4.121892213821411\n","total time 2.887873649597168\n","epoch:  15, step:  500, speed: 168.67ms/b, train loss: 0.023\n","total time 9.184674263000488\n","total time 4.7340803146362305\n","epoch:  17, step:  600, speed: 145.16ms/b, train loss: 0.020\n","total time 11.727972507476807\n","epoch:  18, step:  700, speed: 158.01ms/b, train loss: 0.017\n","total time 11.816208124160767\n","epoch:  19, step:  800, speed: 152.43ms/b, train loss: 0.015\n","total time 10.84106183052063\n","total time 4.500201225280762\n","total time 1.1920928955078125e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  21, eval time:  0.71s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 9.568723678588867\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  22, eval time:  0.74s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  23, step:  900, speed: 166.54ms/b, train loss: 0.014\n","total time 10.738195657730103\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  23, eval time:  0.71s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.2248382568359375\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  24, eval time:  0.74s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  25, step: 1000, speed: 173.76ms/b, train loss: 0.015\n","total time 6.570549488067627\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  25, eval time:  0.73s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 8.05100417137146\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  26, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  27, step: 1100, speed: 189.40ms/b, train loss: 0.014\n","total time 6.9793055057525635\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  27, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.2181408405303955\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  28, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 3.088226556777954\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  29, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  30, step: 1200, speed: 180.51ms/b, train loss: 0.013\n","total time 12.078596830368042\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  30, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 11.895485639572144\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  31, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  32, step: 1300, speed: 179.07ms/b, train loss: 0.013\n","total time 7.262677907943726\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  32, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 7.6034252643585205\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  33, eval time:  0.77s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  34, step: 1400, speed: 183.48ms/b, train loss: 0.013\n","total time 9.023014545440674\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  34, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.1316449642181396\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  35, eval time:  0.80s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  36, step: 1500, speed: 156.50ms/b, train loss: 0.014\n","total time 11.917703628540039\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  36, eval time:  0.78s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 8.75397515296936\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  37, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  38, step: 1600, speed: 189.70ms/b, train loss: 0.012\n","total time 5.4185802936553955\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  38, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.5520174503326416\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  39, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.7231972217559814\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  40, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 5.6327526569366455\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  41, eval time:  0.77s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  42, step: 1700, speed: 186.30ms/b, train loss: 0.013\n","total time 12.266703128814697\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  42, eval time:  0.76s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.121507406234741\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  43, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 7.322073936462402\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  44, eval time:  0.77s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  45, step: 1800, speed: 192.36ms/b, train loss: 0.011\n","total time 8.392671346664429\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  45, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.5378954410552979\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  46, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  47, step: 1900, speed: 173.18ms/b, train loss: 0.013\n","total time 11.859548091888428\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  47, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 6.676406621932983\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  48, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.291788339614868\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  49, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  50, step: 2000, speed: 182.93ms/b, train loss: 0.011\n","total time 11.913517951965332\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  50, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  51, step: 2100, speed: 159.98ms/b, train loss: 0.014\n","total time 11.736422061920166\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  51, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  52, step: 2200, speed: 169.56ms/b, train loss: 0.012\n","total time 10.365355253219604\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  52, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.39531445503234863\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  53, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.654517889022827\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  54, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 9.173178672790527\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  55, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  56, step: 2300, speed: 185.97ms/b, train loss: 0.013\n","total time 10.878846168518066\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  56, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  57, step: 2400, speed: 162.13ms/b, train loss: 0.012\n","total time 11.443307638168335\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  57, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  58, step: 2500, speed: 166.51ms/b, train loss: 0.012\n","total time 12.203251123428345\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  58, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.6291377544403076\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  59, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.3931071758270264\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  60, eval time:  0.75s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.003044366836548\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  61, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 8.672154426574707\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  62, eval time:  0.75s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  63, step: 2600, speed: 212.46ms/b, train loss: 0.013\n","total time 9.666261672973633\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  63, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  64, step: 2700, speed: 168.41ms/b, train loss: 0.013\n","total time 6.8796117305755615\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  64, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.0423917770385742\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  65, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 3.4847233295440674\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  66, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  67, step: 2800, speed: 184.36ms/b, train loss: 0.012\n","total time 10.98798394203186\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  67, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.34578800201416\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  68, eval time:  0.79s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.506516695022583\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  69, eval time:  0.83s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 12.063324689865112\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  70, eval time:  0.76s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  71, step: 2900, speed: 198.31ms/b, train loss: 0.013\n","total time 9.264555215835571\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  71, eval time:  0.76s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  72, step: 3000, speed: 165.98ms/b, train loss: 0.012\n","total time 7.98167085647583\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  72, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 12.019431829452515\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  73, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.211224317550659\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  74, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  75, step: 3100, speed: 194.22ms/b, train loss: 0.012\n","total time 5.838555574417114\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  75, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  76, step: 3200, speed: 158.57ms/b, train loss: 0.013\n","total time 11.66941499710083\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  76, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 11.449786901473999\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  77, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.071439266204834\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  78, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  79, step: 3300, speed: 176.21ms/b, train loss: 0.012\n","total time 3.2679500579833984\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  79, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 6.8509581089019775\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  80, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 3.5281693935394287\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  81, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  82, step: 3400, speed: 192.88ms/b, train loss: 0.012\n","total time 12.086479902267456\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  82, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  83, step: 3500, speed: 157.29ms/b, train loss: 0.012\n","total time 7.736252784729004\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  83, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 10.758214235305786\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  84, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  85, step: 3600, speed: 165.98ms/b, train loss: 0.012\n","total time 11.5257089138031\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  85, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 4.972635746002197\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  86, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  87, step: 3700, speed: 188.10ms/b, train loss: 0.011\n","total time 7.578371047973633\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  87, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 3.4985876083374023\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  88, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.15894055366516113\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  89, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  90, step: 3800, speed: 181.41ms/b, train loss: 0.013\n","total time 9.449973821640015\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  90, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.0850751399993896\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  91, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 8.968504667282104\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  92, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 3.4508280754089355\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  93, eval time:  0.77s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  94, step: 3900, speed: 197.35ms/b, train loss: 0.012\n","total time 12.317945957183838\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  94, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  95, step: 4000, speed: 171.91ms/b, train loss: 0.013\n","total time 11.78073763847351\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  95, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  96, step: 4100, speed: 160.78ms/b, train loss: 0.013\n","total time 10.503636121749878\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  96, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 8.168704271316528\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  97, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.1920928955078125e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  98, eval time:  0.71s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch:  99, step: 4200, speed: 189.80ms/b, train loss: 0.012\n","total time 8.940838098526001\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch  99, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 5.6445019245147705\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 100, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 5.664310693740845\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 101, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 102, step: 4300, speed: 182.12ms/b, train loss: 0.013\n","total time 5.382413864135742\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 102, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.4426372051239014\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 103, eval time:  0.84s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 104, step: 4400, speed: 184.62ms/b, train loss: 0.011\n","total time 10.521529912948608\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 104, eval time:  0.81s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.9578089714050293\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 105, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 9.597143650054932\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 106, eval time:  0.80s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.6362779140472412\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 107, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 108, step: 4500, speed: 192.67ms/b, train loss: 0.012\n","total time 0.9005658626556396\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 108, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 3.312087297439575\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 109, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.280325174331665\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 110, eval time:  0.79s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 111, step: 4600, speed: 179.66ms/b, train loss: 0.013\n","total time 12.286890506744385\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 111, eval time:  0.78s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 10.5226309299469\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 112, eval time:  0.77s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 113, step: 4700, speed: 186.03ms/b, train loss: 0.012\n","total time 6.434746265411377\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 113, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 4.666686773300171\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 114, eval time:  0.79s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 115, step: 4800, speed: 161.39ms/b, train loss: 0.013\n","total time 11.738356828689575\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 115, eval time:  0.76s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 4.12379002571106\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 116, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 117, step: 4900, speed: 186.17ms/b, train loss: 0.011\n","total time 7.092449188232422\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 117, eval time:  0.80s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 11.890238761901855\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 118, eval time:  0.81s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 119, step: 5000, speed: 171.09ms/b, train loss: 0.012\n","total time 2.432620048522949\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 119, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 11.93563985824585\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 120, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.9469819068908691\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 121, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 122, step: 5100, speed: 182.32ms/b, train loss: 0.013\n","total time 3.923579216003418\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 122, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.8490359783172607\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 123, eval time:  0.87s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.4408600330352783\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 124, eval time:  0.73s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 7.270017862319946\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 125, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.1920928955078125e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 126, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 127, step: 5200, speed: 208.49ms/b, train loss: 0.013\n","total time 6.4788079261779785\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 127, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.8004474639892578\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 128, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 8.871132135391235\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 129, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.182661533355713\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 130, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 131, step: 5300, speed: 192.39ms/b, train loss: 0.012\n","total time 0.38185644149780273\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 131, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.2209808826446533\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 132, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.6435985565185547\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 133, eval time:  0.79s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.4116244316101074\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 134, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 3.1364495754241943\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 135, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.0478193759918213\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 136, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.949049472808838\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 137, eval time:  0.79s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 138, step: 5400, speed: 218.99ms/b, train loss: 0.012\n","total time 12.23676872253418\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 138, eval time:  0.76s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.3798017501831055\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 139, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.8992996215820312\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 140, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.602308988571167\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 141, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 0.46515679359436035\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 142, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 143, step: 5500, speed: 203.44ms/b, train loss: 0.012\n","total time 7.617037773132324\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 143, eval time:  0.67s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.430511474609375e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 144, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 2.9611785411834717\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 145, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.531252145767212\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 146, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 147, step: 5600, speed: 182.51ms/b, train loss: 0.013\n","total time 12.172058343887329\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 147, eval time:  0.71s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.4921526908874512\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 148, eval time:  0.82s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 149, step: 5700, speed: 181.28ms/b, train loss: 0.011\n","total time 11.521913051605225\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 149, eval time:  0.83s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 8.691706895828247\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 150, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 151, step: 5800, speed: 174.88ms/b, train loss: 0.012\n","total time 5.058318138122559\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 151, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 10.649178743362427\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 152, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 153, step: 5900, speed: 186.48ms/b, train loss: 0.012\n","total time 5.182027816772461\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 153, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 4.709646224975586\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 154, eval time:  0.84s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 3.4914231300354004\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 155, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 156, step: 6000, speed: 177.50ms/b, train loss: 0.012\n","total time 7.852591276168823\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 156, eval time:  0.72s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 1.1920928955078125e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 157, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 12.1744863986969\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 158, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 159, step: 6100, speed: 179.76ms/b, train loss: 0.011\n","total time 7.970366954803467\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 159, eval time:  0.77s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 160, step: 6200, speed: 157.22ms/b, train loss: 0.009\n","total time 11.536593198776245\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 160, eval time:  0.71s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 11.626348972320557\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 161, eval time:  0.79s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 162, step: 6300, speed: 188.40ms/b, train loss: 0.009\n","total time 12.392053842544556\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 162, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 163, step: 6400, speed: 163.09ms/b, train loss: 0.008\n","total time 10.974849700927734\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   1, gold_num:  51\n","epoch 163, eval time:  0.68s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 6.800337791442871\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   2, gold_num:  51\n","epoch 164, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 165, step: 6500, speed: 173.33ms/b, train loss: 0.008\n","total time 4.023460626602173\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 165, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 5.108225584030151\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   2, gold_num:  51\n","epoch 166, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 167, step: 6600, speed: 187.34ms/b, train loss: 0.007\n","total time 10.662459373474121\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   1, gold_num:  51\n","epoch 167, eval time:  0.70s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 12.057528972625732\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 168, eval time:  0.69s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 169, step: 6700, speed: 172.37ms/b, train loss: 0.006\n","total time 8.930103540420532\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   4, gold_num:  51\n","epoch 169, eval time:  0.77s, f1: 0.000, precision: 0.000, recall: 0.000\n","total time 9.04621410369873\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   1, predict_num:   5, gold_num:  51\n","epoch 170, eval time:  0.71s, f1: 0.036, precision: 0.200, recall: 0.020\n","saving the model, epoch: 170, precision: 0.200, recall: 0.020, best f1: 0.036\n","epoch: 171, step: 6800, speed: 202.97ms/b, train loss: 0.005\n","total time 5.896579742431641\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   3, predict_num:  13, gold_num:  51\n","epoch 171, eval time:  0.70s, f1: 0.094, precision: 0.231, recall: 0.059\n","saving the model, epoch: 171, precision: 0.231, recall: 0.059, best f1: 0.094\n","total time 9.399982213973999\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   0, predict_num:   0, gold_num:  51\n","epoch 172, eval time:  0.77s, f1: 0.000, precision: 0.000, recall: 0.000\n","epoch: 173, step: 6900, speed: 206.58ms/b, train loss: 0.005\n","total time 1.4926929473876953\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   3, predict_num:  14, gold_num:  51\n","epoch 173, eval time:  0.78s, f1: 0.092, precision: 0.214, recall: 0.059\n","total time 12.300596237182617\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   1, predict_num:   2, gold_num:  51\n","epoch 174, eval time:  0.69s, f1: 0.038, precision: 0.500, recall: 0.020\n","total time 0.20738601684570312\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   1, predict_num:   2, gold_num:  51\n","epoch 175, eval time:  0.71s, f1: 0.038, precision: 0.500, recall: 0.020\n","epoch: 176, step: 7000, speed: 178.00ms/b, train loss: 0.006\n","total time 12.024477005004883\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   3, predict_num:   4, gold_num:  51\n","epoch 176, eval time:  0.70s, f1: 0.109, precision: 0.750, recall: 0.059\n","saving the model, epoch: 176, precision: 0.750, recall: 0.059, best f1: 0.109\n","total time 0.6616747379302979\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   1, predict_num:   4, gold_num:  51\n","epoch 177, eval time:  0.77s, f1: 0.036, precision: 0.250, recall: 0.020\n","epoch: 178, step: 7100, speed: 194.94ms/b, train loss: 0.005\n","total time 9.39308214187622\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   3, predict_num:   3, gold_num:  51\n","epoch 178, eval time:  0.77s, f1: 0.111, precision: 1.000, recall: 0.059\n","saving the model, epoch: 178, precision: 1.000, recall: 0.059, best f1: 0.111\n","total time 1.4544100761413574\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   4, predict_num:  10, gold_num:  51\n","epoch 179, eval time:  0.80s, f1: 0.131, precision: 0.400, recall: 0.078\n","saving the model, epoch: 179, precision: 0.400, recall: 0.078, best f1: 0.131\n","total time 0.7845327854156494\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   4, predict_num:  12, gold_num:  51\n","epoch 180, eval time:  0.70s, f1: 0.127, precision: 0.333, recall: 0.078\n","epoch: 181, step: 7200, speed: 228.18ms/b, train loss: 0.005\n","total time 11.277276039123535\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   4, predict_num:  11, gold_num:  51\n","epoch 181, eval time:  0.71s, f1: 0.129, precision: 0.364, recall: 0.078\n","total time 9.308540105819702\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   4, predict_num:   8, gold_num:  51\n","epoch 182, eval time:  0.79s, f1: 0.136, precision: 0.500, recall: 0.078\n","saving the model, epoch: 182, precision: 0.500, recall: 0.078, best f1: 0.136\n","total time 1.430511474609375e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   4, predict_num:   8, gold_num:  51\n","epoch 183, eval time:  0.83s, f1: 0.136, precision: 0.500, recall: 0.078\n","total time 2.179777145385742\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   5, predict_num:   7, gold_num:  51\n","epoch 184, eval time:  1.00s, f1: 0.172, precision: 0.714, recall: 0.098\n","saving the model, epoch: 184, precision: 0.714, recall: 0.098, best f1: 0.172\n","epoch: 185, step: 7300, speed: 229.83ms/b, train loss: 0.004\n","total time 6.297860145568848\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   5, predict_num:   6, gold_num:  51\n","epoch 185, eval time:  0.71s, f1: 0.175, precision: 0.833, recall: 0.098\n","saving the model, epoch: 185, precision: 0.833, recall: 0.098, best f1: 0.175\n","total time 2.8713974952697754\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   6, predict_num:  14, gold_num:  51\n","epoch 186, eval time:  0.71s, f1: 0.185, precision: 0.429, recall: 0.118\n","saving the model, epoch: 186, precision: 0.429, recall: 0.118, best f1: 0.185\n","total time 4.42522406578064\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   6, predict_num:  12, gold_num:  51\n","epoch 187, eval time:  0.70s, f1: 0.190, precision: 0.500, recall: 0.118\n","saving the model, epoch: 187, precision: 0.500, recall: 0.118, best f1: 0.190\n","total time 4.918187856674194\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   4, predict_num:   7, gold_num:  51\n","epoch 188, eval time:  0.77s, f1: 0.138, precision: 0.571, recall: 0.078\n","epoch: 189, step: 7400, speed: 256.60ms/b, train loss: 0.004\n","total time 1.0807852745056152\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   5, predict_num:  10, gold_num:  51\n","epoch 189, eval time:  0.95s, f1: 0.164, precision: 0.500, recall: 0.098\n","total time 10.788166284561157\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   3, predict_num:   3, gold_num:  51\n","epoch 190, eval time:  0.70s, f1: 0.111, precision: 1.000, recall: 0.059\n","total time 4.8153769969940186\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   5, predict_num:  13, gold_num:  51\n","epoch 191, eval time:  0.71s, f1: 0.156, precision: 0.385, recall: 0.098\n","epoch: 192, step: 7500, speed: 200.61ms/b, train loss: 0.004\n","total time 6.44716215133667\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   5, predict_num:   9, gold_num:  51\n","epoch 192, eval time:  0.74s, f1: 0.167, precision: 0.556, recall: 0.098\n","epoch: 193, step: 7600, speed: 168.76ms/b, train loss: 0.004\n","total time 12.244070768356323\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   5, predict_num:  11, gold_num:  51\n","epoch 193, eval time:  0.81s, f1: 0.161, precision: 0.455, recall: 0.098\n","total time 11.756608247756958\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   7, predict_num:   9, gold_num:  51\n","epoch 194, eval time:  0.80s, f1: 0.233, precision: 0.778, recall: 0.137\n","saving the model, epoch: 194, precision: 0.778, recall: 0.137, best f1: 0.233\n","total time 0.8212265968322754\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   7, predict_num:   9, gold_num:  51\n","epoch 195, eval time:  0.71s, f1: 0.233, precision: 0.778, recall: 0.137\n","epoch: 196, step: 7700, speed: 209.13ms/b, train loss: 0.003\n","total time 5.059093952178955\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   9, predict_num:  22, gold_num:  51\n","epoch 196, eval time:  0.71s, f1: 0.247, precision: 0.409, recall: 0.176\n","saving the model, epoch: 196, precision: 0.409, recall: 0.176, best f1: 0.247\n","total time 10.60891604423523\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   8, predict_num:  13, gold_num:  51\n","epoch 197, eval time:  0.78s, f1: 0.250, precision: 0.615, recall: 0.157\n","saving the model, epoch: 197, precision: 0.615, recall: 0.157, best f1: 0.250\n","epoch: 198, step: 7800, speed: 212.34ms/b, train loss: 0.003\n","total time 3.4334046840667725\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  10, predict_num:  19, gold_num:  51\n","epoch 198, eval time:  0.71s, f1: 0.286, precision: 0.526, recall: 0.196\n","saving the model, epoch: 198, precision: 0.526, recall: 0.196, best f1: 0.286\n","total time 4.835493326187134\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  11, predict_num:  28, gold_num:  51\n","epoch 199, eval time:  0.72s, f1: 0.278, precision: 0.393, recall: 0.216\n","total time 8.052319765090942\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  10, predict_num:  22, gold_num:  51\n","epoch 200, eval time:  0.70s, f1: 0.274, precision: 0.455, recall: 0.196\n","epoch: 201, step: 7900, speed: 248.00ms/b, train loss: 0.003\n","total time 4.620053052902222\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  38, gold_num:  51\n","epoch 201, eval time:  0.74s, f1: 0.292, precision: 0.342, recall: 0.255\n","saving the model, epoch: 201, precision: 0.342, recall: 0.255, best f1: 0.292\n","epoch: 202, step: 8000, speed: 183.02ms/b, train loss: 0.003\n","total time 12.646465063095093\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  12, predict_num:  22, gold_num:  51\n","epoch 202, eval time:  0.80s, f1: 0.329, precision: 0.545, recall: 0.235\n","saving the model, epoch: 202, precision: 0.545, recall: 0.235, best f1: 0.329\n","total time 5.699798107147217\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  11, predict_num:  20, gold_num:  51\n","epoch 203, eval time:  0.83s, f1: 0.310, precision: 0.550, recall: 0.216\n","total time 5.621064186096191\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  26, gold_num:  51\n","epoch 204, eval time:  0.76s, f1: 0.338, precision: 0.500, recall: 0.255\n","saving the model, epoch: 204, precision: 0.500, recall: 0.255, best f1: 0.338\n","epoch: 205, step: 8100, speed: 236.56ms/b, train loss: 0.002\n","total time 8.360186338424683\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  25, gold_num:  51\n","epoch 205, eval time:  0.81s, f1: 0.342, precision: 0.520, recall: 0.255\n","saving the model, epoch: 205, precision: 0.520, recall: 0.255, best f1: 0.342\n","total time 7.239539861679077\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:   9, predict_num:  13, gold_num:  51\n","epoch 206, eval time:  0.79s, f1: 0.281, precision: 0.692, recall: 0.176\n","epoch: 207, step: 8200, speed: 199.48ms/b, train loss: 0.002\n","total time 12.450584173202515\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  12, predict_num:  27, gold_num:  51\n","epoch 207, eval time:  0.71s, f1: 0.308, precision: 0.444, recall: 0.235\n","epoch: 208, step: 8300, speed: 165.24ms/b, train loss: 0.002\n","total time 12.482218265533447\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  15, predict_num:  27, gold_num:  51\n","epoch 208, eval time:  0.71s, f1: 0.385, precision: 0.556, recall: 0.294\n","saving the model, epoch: 208, precision: 0.556, recall: 0.294, best f1: 0.385\n","total time 2.976902723312378\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  22, gold_num:  51\n","epoch 209, eval time:  0.86s, f1: 0.356, precision: 0.591, recall: 0.255\n","total time 2.8249659538269043\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  22, gold_num:  51\n","epoch 210, eval time:  0.69s, f1: 0.356, precision: 0.591, recall: 0.255\n","total time 3.450289726257324\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  12, predict_num:  17, gold_num:  51\n","epoch 211, eval time:  0.79s, f1: 0.353, precision: 0.706, recall: 0.235\n","epoch: 212, step: 8400, speed: 220.71ms/b, train loss: 0.002\n","total time 12.28922724723816\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  12, predict_num:  23, gold_num:  51\n","epoch 212, eval time:  0.84s, f1: 0.324, precision: 0.522, recall: 0.235\n","total time 2.2316067218780518\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  12, predict_num:  21, gold_num:  51\n","epoch 213, eval time:  0.81s, f1: 0.333, precision: 0.571, recall: 0.235\n","epoch: 214, step: 8500, speed: 184.62ms/b, train loss: 0.002\n","total time 5.797319173812866\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  22, gold_num:  51\n","epoch 214, eval time:  0.69s, f1: 0.356, precision: 0.591, recall: 0.255\n","total time 1.3658947944641113\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  12, predict_num:  25, gold_num:  51\n","epoch 215, eval time:  0.70s, f1: 0.316, precision: 0.480, recall: 0.235\n","epoch: 216, step: 8600, speed: 170.50ms/b, train loss: 0.002\n","total time 10.281821727752686\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  18, gold_num:  51\n","epoch 216, eval time:  0.70s, f1: 0.377, precision: 0.722, recall: 0.255\n","total time 1.5600767135620117\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  14, predict_num:  23, gold_num:  51\n","epoch 217, eval time:  0.71s, f1: 0.378, precision: 0.609, recall: 0.275\n","total time 5.373575687408447\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  12, predict_num:  16, gold_num:  51\n","epoch 218, eval time:  0.70s, f1: 0.358, precision: 0.750, recall: 0.235\n","total time 2.154062271118164\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  36, gold_num:  51\n","epoch 219, eval time:  0.71s, f1: 0.299, precision: 0.361, recall: 0.255\n","total time 0.901724100112915\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  14, predict_num:  34, gold_num:  51\n","epoch 220, eval time:  0.71s, f1: 0.329, precision: 0.412, recall: 0.275\n","total time 9.5367431640625e-07\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  14, predict_num:  34, gold_num:  51\n","epoch 221, eval time:  0.74s, f1: 0.329, precision: 0.412, recall: 0.275\n","epoch: 222, step: 8700, speed: 211.63ms/b, train loss: 0.002\n","total time 6.567025423049927\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  19, gold_num:  51\n","epoch 222, eval time:  0.70s, f1: 0.371, precision: 0.684, recall: 0.255\n","total time 8.765265226364136\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  15, predict_num:  27, gold_num:  51\n","epoch 223, eval time:  0.84s, f1: 0.385, precision: 0.556, recall: 0.294\n","total time 3.2319233417510986\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  12, predict_num:  19, gold_num:  51\n","epoch 224, eval time:  0.72s, f1: 0.343, precision: 0.632, recall: 0.235\n","epoch: 225, step: 8800, speed: 191.94ms/b, train loss: 0.001\n","total time 5.8327553272247314\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  11, predict_num:  21, gold_num:  51\n","epoch 225, eval time:  0.81s, f1: 0.306, precision: 0.524, recall: 0.216\n","epoch: 226, step: 8900, speed: 167.58ms/b, train loss: 0.002\n","total time 12.338208436965942\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  39, gold_num:  51\n","epoch 226, eval time:  0.82s, f1: 0.400, precision: 0.462, recall: 0.353\n","saving the model, epoch: 226, precision: 0.462, recall: 0.353, best f1: 0.400\n","total time 4.735090732574463\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  15, predict_num:  27, gold_num:  51\n","epoch 227, eval time:  0.68s, f1: 0.385, precision: 0.556, recall: 0.294\n","total time 4.51324462890625\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  14, predict_num:  23, gold_num:  51\n","epoch 228, eval time:  0.98s, f1: 0.378, precision: 0.609, recall: 0.275\n","total time 2.7164998054504395\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  15, predict_num:  24, gold_num:  51\n","epoch 229, eval time:  0.77s, f1: 0.400, precision: 0.625, recall: 0.294\n","saving the model, epoch: 229, precision: 0.625, recall: 0.294, best f1: 0.400\n","epoch: 230, step: 9000, speed: 257.60ms/b, train loss: 0.001\n","total time 6.38813853263855\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  29, gold_num:  51\n","epoch 230, eval time:  1.05s, f1: 0.425, precision: 0.586, recall: 0.333\n","saving the model, epoch: 230, precision: 0.586, recall: 0.333, best f1: 0.425\n","total time 2.244187593460083\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  32, gold_num:  51\n","epoch 231, eval time:  0.71s, f1: 0.410, precision: 0.531, recall: 0.333\n","total time 5.857436895370483\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 232, eval time:  0.94s, f1: 0.436, precision: 0.630, recall: 0.333\n","saving the model, epoch: 232, precision: 0.630, recall: 0.333, best f1: 0.436\n","total time 0.14514422416687012\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 233, eval time:  0.72s, f1: 0.436, precision: 0.630, recall: 0.333\n","total time 3.813117742538452\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  24, gold_num:  51\n","epoch 234, eval time:  0.74s, f1: 0.427, precision: 0.667, recall: 0.314\n","epoch: 235, step: 9100, speed: 252.83ms/b, train loss: 0.001\n","total time 10.607365846633911\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  29, gold_num:  51\n","epoch 235, eval time:  0.70s, f1: 0.400, precision: 0.552, recall: 0.314\n","total time 0.2279491424560547\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  28, gold_num:  51\n","epoch 236, eval time:  0.71s, f1: 0.405, precision: 0.571, recall: 0.314\n","total time 7.566135406494141\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  24, gold_num:  51\n","epoch 237, eval time:  0.72s, f1: 0.427, precision: 0.667, recall: 0.314\n","epoch: 238, step: 9200, speed: 197.49ms/b, train loss: 0.001\n","total time 12.04399585723877\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  15, predict_num:  19, gold_num:  51\n","epoch 238, eval time:  0.70s, f1: 0.429, precision: 0.789, recall: 0.294\n","total time 3.570413112640381\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  30, gold_num:  51\n","epoch 239, eval time:  0.71s, f1: 0.395, precision: 0.533, recall: 0.314\n","epoch: 240, step: 9300, speed: 166.16ms/b, train loss: 0.001\n","total time 1.884758710861206\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  33, gold_num:  51\n","epoch 240, eval time:  0.71s, f1: 0.381, precision: 0.485, recall: 0.314\n","total time 11.29538869857788\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  26, gold_num:  51\n","epoch 241, eval time:  0.69s, f1: 0.468, precision: 0.692, recall: 0.353\n","saving the model, epoch: 241, precision: 0.692, recall: 0.353, best f1: 0.468\n","epoch: 242, step: 9400, speed: 184.81ms/b, train loss: 0.001\n","total time 2.4403493404388428\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  15, predict_num:  23, gold_num:  51\n","epoch 242, eval time:  0.78s, f1: 0.405, precision: 0.652, recall: 0.294\n","total time 12.137980222702026\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  37, gold_num:  51\n","epoch 243, eval time:  0.82s, f1: 0.432, precision: 0.514, recall: 0.373\n","epoch: 244, step: 9500, speed: 187.05ms/b, train loss: 0.001\n","total time 5.565482139587402\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  32, gold_num:  51\n","epoch 244, eval time:  0.71s, f1: 0.458, precision: 0.594, recall: 0.373\n","total time 12.27790093421936\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  25, gold_num:  51\n","epoch 245, eval time:  0.73s, f1: 0.421, precision: 0.640, recall: 0.314\n","epoch: 246, step: 9600, speed: 166.28ms/b, train loss: 0.001\n","total time 8.941725254058838\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  25, gold_num:  51\n","epoch 246, eval time:  0.70s, f1: 0.421, precision: 0.640, recall: 0.314\n","total time 5.075368881225586\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  33, gold_num:  51\n","epoch 247, eval time:  0.71s, f1: 0.429, precision: 0.545, recall: 0.353\n","total time 3.6141819953918457\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  30, gold_num:  51\n","epoch 248, eval time:  0.70s, f1: 0.395, precision: 0.533, recall: 0.314\n","epoch: 249, step: 9700, speed: 205.16ms/b, train loss: 0.001\n","total time 4.385889291763306\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  22, gold_num:  51\n","epoch 249, eval time:  0.73s, f1: 0.438, precision: 0.727, recall: 0.314\n","total time 7.397989273071289\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  37, gold_num:  51\n","epoch 250, eval time:  0.71s, f1: 0.409, precision: 0.486, recall: 0.353\n","total time 4.865629196166992\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 251, eval time:  0.71s, f1: 0.442, precision: 0.654, recall: 0.333\n","epoch: 252, step: 9800, speed: 186.83ms/b, train loss: 0.001\n","total time 10.91179871559143\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  25, gold_num:  51\n","epoch 252, eval time:  0.73s, f1: 0.447, precision: 0.680, recall: 0.333\n","total time 1.4302375316619873\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  33, gold_num:  51\n","epoch 253, eval time:  0.70s, f1: 0.452, precision: 0.576, recall: 0.373\n","epoch: 254, step: 9900, speed: 184.62ms/b, train loss: 0.001\n","total time 7.948718070983887\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  21, predict_num:  42, gold_num:  51\n","epoch 254, eval time:  0.72s, f1: 0.452, precision: 0.500, recall: 0.412\n","total time 3.668632745742798\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  31, gold_num:  51\n","epoch 255, eval time:  0.71s, f1: 0.488, precision: 0.645, recall: 0.392\n","saving the model, epoch: 255, precision: 0.645, recall: 0.392, best f1: 0.488\n","total time 5.253422975540161\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  37, gold_num:  51\n","epoch 256, eval time:  0.68s, f1: 0.432, precision: 0.514, recall: 0.373\n","total time 0.9999217987060547\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  35, gold_num:  51\n","epoch 257, eval time:  0.80s, f1: 0.465, precision: 0.571, recall: 0.392\n","total time 2.745882034301758\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  23, gold_num:  51\n","epoch 258, eval time:  1.03s, f1: 0.432, precision: 0.696, recall: 0.314\n","epoch: 259, step: 10000, speed: 240.03ms/b, train loss: 0.001\n","total time 11.667473077774048\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  26, gold_num:  51\n","epoch 259, eval time:  0.80s, f1: 0.468, precision: 0.692, recall: 0.353\n","epoch: 260, step: 10100, speed: 163.10ms/b, train loss: 0.001\n","total time 7.0450122356414795\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  30, gold_num:  51\n","epoch 260, eval time:  0.71s, f1: 0.469, precision: 0.633, recall: 0.373\n","total time 7.329077482223511\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  30, gold_num:  51\n","epoch 261, eval time:  0.70s, f1: 0.469, precision: 0.633, recall: 0.373\n","epoch: 262, step: 10200, speed: 194.34ms/b, train loss: 0.001\n","total time 12.38100290298462\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 262, eval time:  0.70s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 3.7878732681274414\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  36, gold_num:  51\n","epoch 263, eval time:  0.69s, f1: 0.437, precision: 0.528, recall: 0.373\n","total time 5.4097301959991455\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 264, eval time:  0.84s, f1: 0.434, precision: 0.562, recall: 0.353\n","epoch: 265, step: 10300, speed: 179.41ms/b, train loss: 0.001\n","total time 4.985131502151489\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  30, gold_num:  51\n","epoch 265, eval time:  0.69s, f1: 0.444, precision: 0.600, recall: 0.353\n","total time 4.968628168106079\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  38, gold_num:  51\n","epoch 266, eval time:  0.79s, f1: 0.449, precision: 0.526, recall: 0.392\n","total time 0.6409645080566406\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  38, gold_num:  51\n","epoch 267, eval time:  0.73s, f1: 0.449, precision: 0.526, recall: 0.392\n","epoch: 268, step: 10400, speed: 180.29ms/b, train loss: 0.001\n","total time 12.021635055541992\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  30, gold_num:  51\n","epoch 268, eval time:  0.70s, f1: 0.444, precision: 0.600, recall: 0.353\n","epoch: 269, step: 10500, speed: 158.79ms/b, train loss: 0.001\n","total time 10.762444019317627\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  41, gold_num:  51\n","epoch 269, eval time:  0.84s, f1: 0.413, precision: 0.463, recall: 0.373\n","total time 9.156655311584473\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  32, gold_num:  51\n","epoch 270, eval time:  0.71s, f1: 0.458, precision: 0.594, recall: 0.373\n","total time 1.839690923690796\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  29, gold_num:  51\n","epoch 271, eval time:  0.85s, f1: 0.475, precision: 0.655, recall: 0.373\n","epoch: 272, step: 10600, speed: 190.19ms/b, train loss: 0.001\n","total time 4.243496656417847\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  35, gold_num:  51\n","epoch 272, eval time:  0.71s, f1: 0.442, precision: 0.543, recall: 0.373\n","total time 4.9895408153533936\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 273, eval time:  0.79s, f1: 0.447, precision: 0.559, recall: 0.373\n","total time 5.237470865249634\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  25, gold_num:  51\n","epoch 274, eval time:  0.70s, f1: 0.447, precision: 0.680, recall: 0.333\n","total time 1.430511474609375e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  25, gold_num:  51\n","epoch 275, eval time:  0.72s, f1: 0.447, precision: 0.680, recall: 0.333\n","epoch: 276, step: 10700, speed: 195.32ms/b, train loss: 0.001\n","total time 4.4955735206604\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  31, gold_num:  51\n","epoch 276, eval time:  0.80s, f1: 0.439, precision: 0.581, recall: 0.353\n","total time 6.724604606628418\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  33, gold_num:  51\n","epoch 277, eval time:  0.78s, f1: 0.452, precision: 0.576, recall: 0.373\n","total time 3.8633475303649902\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  31, gold_num:  51\n","epoch 278, eval time:  0.80s, f1: 0.439, precision: 0.581, recall: 0.353\n","total time 2.041445255279541\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  38, gold_num:  51\n","epoch 279, eval time:  0.71s, f1: 0.427, precision: 0.500, recall: 0.373\n","total time 2.373952865600586\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  33, gold_num:  51\n","epoch 280, eval time:  0.69s, f1: 0.452, precision: 0.576, recall: 0.373\n","epoch: 281, step: 10800, speed: 221.10ms/b, train loss: 0.001\n","total time 4.381536960601807\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  64, gold_num:  51\n","epoch 281, eval time:  0.72s, f1: 0.313, precision: 0.281, recall: 0.353\n","total time 11.896698713302612\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  25, gold_num:  51\n","epoch 282, eval time:  0.70s, f1: 0.447, precision: 0.680, recall: 0.333\n","epoch: 283, step: 10900, speed: 183.64ms/b, train loss: 0.001\n","total time 9.624686002731323\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  31, gold_num:  51\n","epoch 283, eval time:  0.72s, f1: 0.439, precision: 0.581, recall: 0.353\n","total time 1.9495606422424316\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  33, gold_num:  51\n","epoch 284, eval time:  0.72s, f1: 0.429, precision: 0.545, recall: 0.353\n","total time 3.8490891456604004\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 285, eval time:  0.71s, f1: 0.434, precision: 0.562, recall: 0.353\n","total time 0.9216675758361816\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 286, eval time:  0.70s, f1: 0.434, precision: 0.562, recall: 0.353\n","epoch: 287, step: 11000, speed: 203.16ms/b, train loss: 0.000\n","total time 5.0942230224609375\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  34, gold_num:  51\n","epoch 287, eval time:  0.70s, f1: 0.424, precision: 0.529, recall: 0.353\n","total time 1.4337666034698486\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  31, gold_num:  51\n","epoch 288, eval time:  0.84s, f1: 0.415, precision: 0.548, recall: 0.333\n","total time 0.18562793731689453\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  29, gold_num:  51\n","epoch 289, eval time:  0.72s, f1: 0.400, precision: 0.552, recall: 0.314\n","total time 0.6032142639160156\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  29, gold_num:  51\n","epoch 290, eval time:  0.70s, f1: 0.400, precision: 0.552, recall: 0.314\n","total time 1.1364259719848633\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  24, gold_num:  51\n","epoch 291, eval time:  0.70s, f1: 0.427, precision: 0.667, recall: 0.314\n","total time 5.5538952350616455\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  35, gold_num:  51\n","epoch 292, eval time:  0.83s, f1: 0.419, precision: 0.514, recall: 0.353\n","epoch: 293, step: 11100, speed: 224.03ms/b, train loss: 0.001\n","total time 4.409714221954346\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  34, gold_num:  51\n","epoch 293, eval time:  0.73s, f1: 0.424, precision: 0.529, recall: 0.353\n","total time 6.478423595428467\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  28, gold_num:  51\n","epoch 294, eval time:  0.83s, f1: 0.430, precision: 0.607, recall: 0.333\n","epoch: 295, step: 11200, speed: 173.56ms/b, train loss: 0.001\n","total time 12.078060150146484\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  36, gold_num:  51\n","epoch 295, eval time:  0.80s, f1: 0.414, precision: 0.500, recall: 0.353\n","total time 1.069399356842041\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  37, gold_num:  51\n","epoch 296, eval time:  0.70s, f1: 0.432, precision: 0.514, recall: 0.373\n","total time 3.2044692039489746\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  39, gold_num:  51\n","epoch 297, eval time:  0.70s, f1: 0.422, precision: 0.487, recall: 0.373\n","total time 2.9038329124450684\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  28, gold_num:  51\n","epoch 298, eval time:  0.71s, f1: 0.481, precision: 0.679, recall: 0.373\n","epoch: 299, step: 11300, speed: 198.05ms/b, train loss: 0.000\n","total time 11.932141304016113\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 299, eval time:  0.70s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 3.252526044845581\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 300, eval time:  0.81s, f1: 0.450, precision: 0.621, recall: 0.353\n","epoch: 301, step: 11400, speed: 177.42ms/b, train loss: 0.000\n","total time 8.785302639007568\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  28, gold_num:  51\n","epoch 301, eval time:  0.71s, f1: 0.430, precision: 0.607, recall: 0.333\n","total time 3.4811549186706543\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  24, gold_num:  51\n","epoch 302, eval time:  0.70s, f1: 0.453, precision: 0.708, recall: 0.333\n","total time 1.3126320838928223\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 303, eval time:  0.72s, f1: 0.442, precision: 0.654, recall: 0.333\n","total time 1.5172514915466309\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  33, gold_num:  51\n","epoch 304, eval time:  0.71s, f1: 0.452, precision: 0.576, recall: 0.373\n","epoch: 305, step: 11500, speed: 208.91ms/b, train loss: 0.000\n","total time 12.014142990112305\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  32, gold_num:  51\n","epoch 305, eval time:  0.70s, f1: 0.482, precision: 0.625, recall: 0.392\n","epoch: 306, step: 11600, speed: 160.09ms/b, train loss: 0.000\n","total time 11.37193250656128\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  25, gold_num:  51\n","epoch 306, eval time:  0.70s, f1: 0.447, precision: 0.680, recall: 0.333\n","total time 2.700690746307373\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 307, eval time:  0.73s, f1: 0.436, precision: 0.630, recall: 0.333\n","epoch: 308, step: 11700, speed: 155.46ms/b, train loss: 0.000\n","total time 11.984167098999023\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  23, gold_num:  51\n","epoch 308, eval time:  0.70s, f1: 0.459, precision: 0.739, recall: 0.333\n","total time 5.520525932312012\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  21, predict_num:  35, gold_num:  51\n","epoch 309, eval time:  0.71s, f1: 0.488, precision: 0.600, recall: 0.412\n","saving the model, epoch: 309, precision: 0.600, recall: 0.412, best f1: 0.488\n","total time 5.686659812927246\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  28, gold_num:  51\n","epoch 310, eval time:  0.91s, f1: 0.481, precision: 0.679, recall: 0.373\n","epoch: 311, step: 11800, speed: 214.61ms/b, train loss: 0.001\n","total time 4.731505870819092\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 311, eval time:  0.81s, f1: 0.447, precision: 0.559, recall: 0.373\n","total time 1.5860316753387451\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  32, gold_num:  51\n","epoch 312, eval time:  0.72s, f1: 0.458, precision: 0.594, recall: 0.373\n","total time 0.32793474197387695\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  32, gold_num:  51\n","epoch 313, eval time:  0.72s, f1: 0.458, precision: 0.594, recall: 0.373\n","total time 5.647714853286743\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  40, gold_num:  51\n","epoch 314, eval time:  0.70s, f1: 0.440, precision: 0.500, recall: 0.392\n","epoch: 315, step: 11900, speed: 189.11ms/b, train loss: 0.001\n","total time 6.762240648269653\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  24, gold_num:  51\n","epoch 315, eval time:  0.72s, f1: 0.453, precision: 0.708, recall: 0.333\n","total time 7.640990734100342\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 316, eval time:  0.70s, f1: 0.434, precision: 0.562, recall: 0.353\n","total time 2.096186399459839\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  36, gold_num:  51\n","epoch 317, eval time:  0.71s, f1: 0.414, precision: 0.500, recall: 0.353\n","epoch: 318, step: 12000, speed: 208.56ms/b, train loss: 0.000\n","total time 5.91842246055603\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  36, gold_num:  51\n","epoch 318, eval time:  0.70s, f1: 0.414, precision: 0.500, recall: 0.353\n","total time 5.7910237312316895\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 319, eval time:  0.71s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 0.0879814624786377\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 320, eval time:  0.78s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 9.424963474273682\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  35, gold_num:  51\n","epoch 321, eval time:  0.70s, f1: 0.395, precision: 0.486, recall: 0.333\n","epoch: 322, step: 12100, speed: 199.57ms/b, train loss: 0.000\n","total time 3.5037336349487305\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  36, gold_num:  51\n","epoch 322, eval time:  0.83s, f1: 0.437, precision: 0.528, recall: 0.373\n","total time 5.541271924972534\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 323, eval time:  0.70s, f1: 0.447, precision: 0.559, recall: 0.373\n","total time 1.1737596988677979\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  36, gold_num:  51\n","epoch 324, eval time:  0.71s, f1: 0.460, precision: 0.556, recall: 0.392\n","total time 2.931253671646118\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  31, gold_num:  51\n","epoch 325, eval time:  0.84s, f1: 0.463, precision: 0.613, recall: 0.373\n","epoch: 326, step: 12200, speed: 199.56ms/b, train loss: 0.000\n","total time 4.038578510284424\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  30, gold_num:  51\n","epoch 326, eval time:  0.70s, f1: 0.469, precision: 0.633, recall: 0.373\n","total time 12.292261600494385\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 327, eval time:  0.71s, f1: 0.447, precision: 0.559, recall: 0.373\n","epoch: 328, step: 12300, speed: 170.49ms/b, train loss: 0.000\n","total time 6.1891186237335205\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  36, gold_num:  51\n","epoch 328, eval time:  0.79s, f1: 0.437, precision: 0.528, recall: 0.373\n","total time 0.822760820388794\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  38, gold_num:  51\n","epoch 329, eval time:  0.73s, f1: 0.449, precision: 0.526, recall: 0.392\n","epoch: 330, step: 12400, speed: 172.27ms/b, train loss: 0.000\n","total time 11.580972671508789\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  32, gold_num:  51\n","epoch 330, eval time:  0.70s, f1: 0.482, precision: 0.625, recall: 0.392\n","total time 2.794260263442993\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  28, gold_num:  51\n","epoch 331, eval time:  0.71s, f1: 0.430, precision: 0.607, recall: 0.333\n","epoch: 332, step: 12500, speed: 181.10ms/b, train loss: 0.000\n","total time 12.346571683883667\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  31, gold_num:  51\n","epoch 332, eval time:  0.71s, f1: 0.463, precision: 0.613, recall: 0.373\n","total time 2.120918035507202\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  36, gold_num:  51\n","epoch 333, eval time:  0.70s, f1: 0.460, precision: 0.556, recall: 0.392\n","total time 3.133413076400757\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  30, gold_num:  51\n","epoch 334, eval time:  0.82s, f1: 0.469, precision: 0.633, recall: 0.373\n","total time 1.6689300537109375e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  30, gold_num:  51\n","epoch 335, eval time:  0.76s, f1: 0.469, precision: 0.633, recall: 0.373\n","total time 0.23357629776000977\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  26, gold_num:  51\n","epoch 336, eval time:  0.73s, f1: 0.494, precision: 0.731, recall: 0.373\n","saving the model, epoch: 336, precision: 0.731, recall: 0.373, best f1: 0.494\n","total time 3.7076807022094727\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  31, gold_num:  51\n","epoch 337, eval time:  0.70s, f1: 0.415, precision: 0.548, recall: 0.333\n","total time 0.6074681282043457\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  15, predict_num:  19, gold_num:  51\n","epoch 338, eval time:  0.71s, f1: 0.429, precision: 0.789, recall: 0.294\n","total time 0.43799352645874023\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  15, gold_num:  51\n","epoch 339, eval time:  0.82s, f1: 0.394, precision: 0.867, recall: 0.255\n","epoch: 340, step: 12600, speed: 269.91ms/b, train loss: 0.001\n","total time 10.286834001541138\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 340, eval time:  0.70s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 0.44827842712402344\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  28, gold_num:  51\n","epoch 341, eval time:  0.81s, f1: 0.456, precision: 0.643, recall: 0.353\n","epoch: 342, step: 12700, speed: 172.03ms/b, train loss: 0.001\n","total time 11.776107788085938\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  24, gold_num:  51\n","epoch 342, eval time:  0.80s, f1: 0.480, precision: 0.750, recall: 0.353\n","total time 11.025651216506958\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  24, gold_num:  51\n","epoch 343, eval time:  0.72s, f1: 0.507, precision: 0.792, recall: 0.373\n","saving the model, epoch: 343, precision: 0.792, recall: 0.373, best f1: 0.507\n","epoch: 344, step: 12800, speed: 196.87ms/b, train loss: 0.000\n","total time 5.638840198516846\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  28, gold_num:  51\n","epoch 344, eval time:  0.70s, f1: 0.506, precision: 0.714, recall: 0.392\n","total time 2.3553497791290283\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  21, gold_num:  51\n","epoch 345, eval time:  0.78s, f1: 0.500, precision: 0.857, recall: 0.353\n","total time 0.3025052547454834\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  22, gold_num:  51\n","epoch 346, eval time:  0.84s, f1: 0.493, precision: 0.818, recall: 0.353\n","total time 1.0683066844940186\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  40, gold_num:  51\n","epoch 347, eval time:  0.93s, f1: 0.440, precision: 0.500, recall: 0.392\n","total time 2.0433101654052734\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  35, gold_num:  51\n","epoch 348, eval time:  0.79s, f1: 0.442, precision: 0.543, recall: 0.373\n","total time 0.18197870254516602\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 349, eval time:  0.74s, f1: 0.447, precision: 0.559, recall: 0.373\n","total time 2.8495991230010986\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 350, eval time:  0.70s, f1: 0.442, precision: 0.654, recall: 0.333\n","total time 3.3165793418884277\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  24, gold_num:  51\n","epoch 351, eval time:  0.82s, f1: 0.427, precision: 0.667, recall: 0.314\n","epoch: 352, step: 12900, speed: 248.87ms/b, train loss: 0.001\n","total time 12.356848239898682\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  31, gold_num:  51\n","epoch 352, eval time:  0.80s, f1: 0.463, precision: 0.613, recall: 0.373\n","epoch: 353, step: 13000, speed: 168.16ms/b, train loss: 0.000\n","total time 10.296155452728271\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 353, eval time:  0.81s, f1: 0.434, precision: 0.562, recall: 0.353\n","epoch: 354, step: 13100, speed: 161.44ms/b, train loss: 0.000\n","total time 11.950803279876709\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  30, gold_num:  51\n","epoch 354, eval time:  0.79s, f1: 0.444, precision: 0.600, recall: 0.353\n","total time 6.49272084236145\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 355, eval time:  0.71s, f1: 0.434, precision: 0.562, recall: 0.353\n","total time 1.710017204284668\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  25, gold_num:  51\n","epoch 356, eval time:  0.70s, f1: 0.447, precision: 0.680, recall: 0.333\n","total time 4.8007121086120605\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 357, eval time:  0.71s, f1: 0.442, precision: 0.654, recall: 0.333\n","epoch: 358, step: 13200, speed: 194.60ms/b, train loss: 0.000\n","total time 5.645813703536987\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  27, gold_num:  51\n","epoch 358, eval time:  0.69s, f1: 0.410, precision: 0.593, recall: 0.314\n","epoch: 359, step: 13300, speed: 172.92ms/b, train loss: 0.000\n","total time 12.108390808105469\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  31, gold_num:  51\n","epoch 359, eval time:  0.70s, f1: 0.463, precision: 0.613, recall: 0.373\n","total time 9.756813287734985\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 360, eval time:  0.70s, f1: 0.436, precision: 0.630, recall: 0.333\n","total time 4.827418565750122\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  31, gold_num:  51\n","epoch 361, eval time:  0.79s, f1: 0.439, precision: 0.581, recall: 0.353\n","epoch: 362, step: 13400, speed: 193.88ms/b, train loss: 0.000\n","total time 12.15981912612915\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  28, gold_num:  51\n","epoch 362, eval time:  0.79s, f1: 0.405, precision: 0.571, recall: 0.314\n","total time 1.9287569522857666\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  28, gold_num:  51\n","epoch 363, eval time:  0.69s, f1: 0.405, precision: 0.571, recall: 0.314\n","epoch: 364, step: 13500, speed: 183.91ms/b, train loss: 0.000\n","total time 7.250708103179932\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 364, eval time:  0.76s, f1: 0.442, precision: 0.654, recall: 0.333\n","total time 5.472400426864624\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  35, gold_num:  51\n","epoch 365, eval time:  0.70s, f1: 0.419, precision: 0.514, recall: 0.353\n","epoch: 366, step: 13600, speed: 184.27ms/b, train loss: 0.000\n","total time 8.80808687210083\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  21, gold_num:  51\n","epoch 366, eval time:  0.71s, f1: 0.444, precision: 0.762, recall: 0.314\n","total time 12.369948387145996\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 367, eval time:  0.70s, f1: 0.462, precision: 0.667, recall: 0.353\n","epoch: 368, step: 13700, speed: 179.21ms/b, train loss: 0.000\n","total time 4.729542970657349\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  26, gold_num:  51\n","epoch 368, eval time:  0.71s, f1: 0.468, precision: 0.692, recall: 0.353\n","total time 4.538322925567627\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  26, gold_num:  51\n","epoch 369, eval time:  0.83s, f1: 0.468, precision: 0.692, recall: 0.353\n","total time 1.081528663635254\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  26, gold_num:  51\n","epoch 370, eval time:  0.70s, f1: 0.468, precision: 0.692, recall: 0.353\n","total time 2.413795232772827\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  24, gold_num:  51\n","epoch 371, eval time:  0.72s, f1: 0.453, precision: 0.708, recall: 0.333\n","total time 0.9987447261810303\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  24, gold_num:  51\n","epoch 372, eval time:  0.69s, f1: 0.453, precision: 0.708, recall: 0.333\n","epoch: 373, step: 13800, speed: 213.10ms/b, train loss: 0.000\n","total time 5.8511011600494385\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  22, gold_num:  51\n","epoch 373, eval time:  0.70s, f1: 0.466, precision: 0.773, recall: 0.333\n","total time 3.870234489440918\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  20, gold_num:  51\n","epoch 374, eval time:  0.71s, f1: 0.479, precision: 0.850, recall: 0.333\n","total time 0.6011109352111816\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  32, gold_num:  51\n","epoch 375, eval time:  0.70s, f1: 0.410, precision: 0.531, recall: 0.333\n","epoch: 376, step: 13900, speed: 192.33ms/b, train loss: 0.000\n","total time 12.365846872329712\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  26, gold_num:  51\n","epoch 376, eval time:  0.69s, f1: 0.468, precision: 0.692, recall: 0.353\n","total time 8.721625804901123\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 377, eval time:  0.71s, f1: 0.462, precision: 0.667, recall: 0.353\n","epoch: 378, step: 14000, speed: 182.35ms/b, train loss: 0.000\n","total time 6.785994291305542\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  26, gold_num:  51\n","epoch 378, eval time:  0.84s, f1: 0.494, precision: 0.731, recall: 0.373\n","total time 3.8526628017425537\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  25, gold_num:  51\n","epoch 379, eval time:  0.71s, f1: 0.500, precision: 0.760, recall: 0.373\n","total time 4.845653772354126\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  34, gold_num:  51\n","epoch 380, eval time:  0.78s, f1: 0.376, precision: 0.471, recall: 0.314\n","total time 0.7437455654144287\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  38, gold_num:  51\n","epoch 381, eval time:  0.83s, f1: 0.404, precision: 0.474, recall: 0.353\n","total time 0.1512315273284912\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  38, gold_num:  51\n","epoch 382, eval time:  0.74s, f1: 0.404, precision: 0.474, recall: 0.353\n","total time 5.940206527709961\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  42, gold_num:  51\n","epoch 383, eval time:  0.71s, f1: 0.387, precision: 0.429, recall: 0.353\n","epoch: 384, step: 14100, speed: 230.30ms/b, train loss: 0.000\n","total time 4.140906095504761\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 384, eval time:  0.87s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 8.331806659698486\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  36, gold_num:  51\n","epoch 385, eval time:  0.82s, f1: 0.414, precision: 0.500, recall: 0.353\n","epoch: 386, step: 14200, speed: 174.17ms/b, train loss: 0.000\n","total time 7.110419988632202\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  30, gold_num:  51\n","epoch 386, eval time:  0.70s, f1: 0.444, precision: 0.600, recall: 0.353\n","total time 2.5467453002929688\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  28, gold_num:  51\n","epoch 387, eval time:  0.71s, f1: 0.430, precision: 0.607, recall: 0.333\n","total time 2.2539219856262207\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  30, gold_num:  51\n","epoch 388, eval time:  0.75s, f1: 0.444, precision: 0.600, recall: 0.353\n","epoch: 389, step: 14300, speed: 197.69ms/b, train loss: 0.000\n","total time 12.497172117233276\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  26, gold_num:  51\n","epoch 389, eval time:  0.80s, f1: 0.416, precision: 0.615, recall: 0.314\n","total time 4.453132152557373\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 390, eval time:  0.71s, f1: 0.434, precision: 0.562, recall: 0.353\n","epoch: 391, step: 14400, speed: 174.31ms/b, train loss: 0.000\n","total time 11.80620288848877\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  30, gold_num:  51\n","epoch 391, eval time:  0.70s, f1: 0.444, precision: 0.600, recall: 0.353\n","total time 4.08544397354126\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 392, eval time:  0.72s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 5.309666872024536\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  33, gold_num:  51\n","epoch 393, eval time:  0.70s, f1: 0.429, precision: 0.545, recall: 0.353\n","epoch: 394, step: 14500, speed: 184.13ms/b, train loss: 0.000\n","total time 11.998172521591187\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 394, eval time:  0.70s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 5.425273418426514\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 395, eval time:  0.71s, f1: 0.434, precision: 0.562, recall: 0.353\n","epoch: 396, step: 14600, speed: 187.76ms/b, train loss: 0.000\n","total time 11.901731014251709\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 396, eval time:  0.69s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 1.682788372039795\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 397, eval time:  0.82s, f1: 0.450, precision: 0.621, recall: 0.353\n","epoch: 398, step: 14700, speed: 176.54ms/b, train loss: 0.000\n","total time 3.2507083415985107\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 398, eval time:  0.70s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 7.369781494140625\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 399, eval time:  0.78s, f1: 0.434, precision: 0.562, recall: 0.353\n","total time 0.5796661376953125\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  32, gold_num:  51\n","epoch 400, eval time:  0.86s, f1: 0.410, precision: 0.531, recall: 0.333\n","epoch: 401, step: 14800, speed: 183.94ms/b, train loss: 0.000\n","total time 8.119640111923218\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  25, gold_num:  51\n","epoch 401, eval time:  0.72s, f1: 0.421, precision: 0.640, recall: 0.314\n","total time 8.222041845321655\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  31, gold_num:  51\n","epoch 402, eval time:  0.70s, f1: 0.439, precision: 0.581, recall: 0.353\n","epoch: 403, step: 14900, speed: 172.84ms/b, train loss: 0.000\n","total time 8.342175483703613\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 403, eval time:  0.71s, f1: 0.436, precision: 0.630, recall: 0.333\n","total time 11.681391477584839\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  28, gold_num:  51\n","epoch 404, eval time:  0.70s, f1: 0.456, precision: 0.643, recall: 0.353\n","total time 3.5762786865234375e-06\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  28, gold_num:  51\n","epoch 405, eval time:  0.78s, f1: 0.456, precision: 0.643, recall: 0.353\n","epoch: 406, step: 15000, speed: 186.16ms/b, train loss: 0.000\n","total time 9.786469459533691\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 406, eval time:  0.84s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 5.201214790344238\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 407, eval time:  0.69s, f1: 0.442, precision: 0.654, recall: 0.333\n","epoch: 408, step: 15100, speed: 177.59ms/b, train loss: 0.000\n","total time 3.5557897090911865\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 408, eval time:  0.80s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 0.937434196472168\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 409, eval time:  0.86s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 11.454010486602783\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  25, gold_num:  51\n","epoch 410, eval time:  0.82s, f1: 0.421, precision: 0.640, recall: 0.314\n","epoch: 411, step: 15200, speed: 191.72ms/b, train loss: 0.000\n","total time 3.4884610176086426\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  19, gold_num:  51\n","epoch 411, eval time:  0.69s, f1: 0.457, precision: 0.842, recall: 0.314\n","total time 1.1153953075408936\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  20, gold_num:  51\n","epoch 412, eval time:  0.70s, f1: 0.451, precision: 0.800, recall: 0.314\n","total time 8.362061023712158\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  23, gold_num:  51\n","epoch 413, eval time:  0.72s, f1: 0.432, precision: 0.696, recall: 0.314\n","epoch: 414, step: 15300, speed: 197.81ms/b, train loss: 0.000\n","total time 7.945881366729736\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  25, gold_num:  51\n","epoch 414, eval time:  0.85s, f1: 0.474, precision: 0.720, recall: 0.353\n","total time 3.792823076248169\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 415, eval time:  0.71s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 2.7528927326202393\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 416, eval time:  0.71s, f1: 0.436, precision: 0.630, recall: 0.333\n","epoch: 417, step: 15400, speed: 173.41ms/b, train loss: 0.000\n","total time 12.338993072509766\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 417, eval time:  0.71s, f1: 0.442, precision: 0.654, recall: 0.333\n","total time 0.6736786365509033\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  25, gold_num:  51\n","epoch 418, eval time:  0.70s, f1: 0.447, precision: 0.680, recall: 0.333\n","total time 4.815626621246338\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 419, eval time:  0.69s, f1: 0.442, precision: 0.654, recall: 0.333\n","total time 0.3945596218109131\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 420, eval time:  0.70s, f1: 0.442, precision: 0.654, recall: 0.333\n","total time 0.8315470218658447\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 421, eval time:  0.71s, f1: 0.442, precision: 0.654, recall: 0.333\n","total time 1.5161163806915283\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  43, gold_num:  51\n","epoch 422, eval time:  0.70s, f1: 0.383, precision: 0.419, recall: 0.353\n","epoch: 423, step: 15500, speed: 219.40ms/b, train loss: 0.001\n","total time 9.38109016418457\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  17, gold_num:  51\n","epoch 423, eval time:  0.71s, f1: 0.471, precision: 0.941, recall: 0.314\n","epoch: 424, step: 15600, speed: 167.15ms/b, train loss: 0.000\n","total time 11.959567785263062\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 424, eval time:  0.73s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 4.9469990730285645\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  26, gold_num:  51\n","epoch 425, eval time:  0.75s, f1: 0.416, precision: 0.615, recall: 0.314\n","total time 7.013380527496338\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  35, gold_num:  51\n","epoch 426, eval time:  0.71s, f1: 0.442, precision: 0.543, recall: 0.373\n","epoch: 427, step: 15700, speed: 203.19ms/b, train loss: 0.000\n","total time 8.70629096031189\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  33, gold_num:  51\n","epoch 427, eval time:  0.74s, f1: 0.429, precision: 0.545, recall: 0.353\n","epoch: 428, step: 15800, speed: 165.21ms/b, train loss: 0.000\n","total time 11.492495775222778\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  28, gold_num:  51\n","epoch 428, eval time:  0.70s, f1: 0.456, precision: 0.643, recall: 0.353\n","total time 12.077278852462769\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  28, gold_num:  51\n","epoch 429, eval time:  0.70s, f1: 0.405, precision: 0.571, recall: 0.314\n","epoch: 430, step: 15900, speed: 183.02ms/b, train loss: 0.000\n","total time 8.800298929214478\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  28, gold_num:  51\n","epoch 430, eval time:  0.79s, f1: 0.456, precision: 0.643, recall: 0.353\n","total time 3.2431282997131348\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  26, gold_num:  51\n","epoch 431, eval time:  0.71s, f1: 0.416, precision: 0.615, recall: 0.314\n","total time 0.485140323638916\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  26, gold_num:  51\n","epoch 432, eval time:  0.71s, f1: 0.416, precision: 0.615, recall: 0.314\n","epoch: 433, step: 16000, speed: 187.86ms/b, train loss: 0.000\n","total time 12.142838478088379\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  25, gold_num:  51\n","epoch 433, eval time:  0.69s, f1: 0.474, precision: 0.720, recall: 0.353\n","total time 1.246340036392212\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 434, eval time:  0.71s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 4.321409225463867\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  26, gold_num:  51\n","epoch 435, eval time:  0.80s, f1: 0.468, precision: 0.692, recall: 0.353\n","total time 0.3181724548339844\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  26, gold_num:  51\n","epoch 436, eval time:  0.72s, f1: 0.468, precision: 0.692, recall: 0.353\n","epoch: 437, step: 16100, speed: 192.34ms/b, train loss: 0.000\n","total time 10.904509782791138\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 437, eval time:  0.85s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 3.1229605674743652\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 438, eval time:  0.70s, f1: 0.436, precision: 0.630, recall: 0.333\n","epoch: 439, step: 16200, speed: 180.53ms/b, train loss: 0.000\n","total time 10.182043075561523\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  26, gold_num:  51\n","epoch 439, eval time:  0.76s, f1: 0.442, precision: 0.654, recall: 0.333\n","epoch: 440, step: 16300, speed: 163.22ms/b, train loss: 0.000\n","total time 12.13612151145935\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  19, gold_num:  51\n","epoch 440, eval time:  0.70s, f1: 0.457, precision: 0.842, recall: 0.314\n","total time 5.148289442062378\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  31, gold_num:  51\n","epoch 441, eval time:  0.70s, f1: 0.463, precision: 0.613, recall: 0.373\n","total time 5.325947999954224\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  52, gold_num:  51\n","epoch 442, eval time:  0.71s, f1: 0.330, precision: 0.327, recall: 0.333\n","epoch: 443, step: 16400, speed: 196.64ms/b, train loss: 0.000\n","total time 12.157037019729614\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  13, predict_num:  21, gold_num:  51\n","epoch 443, eval time:  0.70s, f1: 0.361, precision: 0.619, recall: 0.255\n","epoch: 444, step: 16500, speed: 158.80ms/b, train loss: 0.000\n","total time 9.224300146102905\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  29, gold_num:  51\n","epoch 444, eval time:  0.82s, f1: 0.400, precision: 0.552, recall: 0.314\n","total time 6.411767482757568\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  39, gold_num:  51\n","epoch 445, eval time:  0.70s, f1: 0.422, precision: 0.487, recall: 0.373\n","total time 2.6074419021606445\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  32, gold_num:  51\n","epoch 446, eval time:  0.77s, f1: 0.410, precision: 0.531, recall: 0.333\n","epoch: 447, step: 16600, speed: 201.46ms/b, train loss: 0.000\n","total time 11.219269752502441\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  47, gold_num:  51\n","epoch 447, eval time:  0.71s, f1: 0.347, precision: 0.362, recall: 0.333\n","total time 1.8993303775787354\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  31, gold_num:  51\n","epoch 448, eval time:  0.85s, f1: 0.415, precision: 0.548, recall: 0.333\n","total time 3.0969631671905518\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  21, gold_num:  51\n","epoch 449, eval time:  0.70s, f1: 0.444, precision: 0.762, recall: 0.314\n","epoch: 450, step: 16700, speed: 186.03ms/b, train loss: 0.001\n","total time 5.314801454544067\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  29, gold_num:  51\n","epoch 450, eval time:  0.72s, f1: 0.425, precision: 0.586, recall: 0.333\n","total time 3.408522367477417\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  15, predict_num:  32, gold_num:  51\n","epoch 451, eval time:  0.71s, f1: 0.361, precision: 0.469, recall: 0.294\n","total time 4.178152799606323\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  28, gold_num:  51\n","epoch 452, eval time:  0.69s, f1: 0.405, precision: 0.571, recall: 0.314\n","total time 4.11078953742981\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  29, gold_num:  51\n","epoch 453, eval time:  0.79s, f1: 0.425, precision: 0.586, recall: 0.333\n","epoch: 454, step: 16800, speed: 197.81ms/b, train loss: 0.000\n","total time 4.868318796157837\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  34, gold_num:  51\n","epoch 454, eval time:  0.70s, f1: 0.400, precision: 0.500, recall: 0.333\n","epoch: 455, step: 16900, speed: 159.20ms/b, train loss: 0.000\n","total time 11.985857486724854\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  30, gold_num:  51\n","epoch 455, eval time:  0.70s, f1: 0.420, precision: 0.567, recall: 0.333\n","total time 11.090917587280273\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 456, eval time:  0.70s, f1: 0.447, precision: 0.559, recall: 0.373\n","epoch: 457, step: 17000, speed: 170.93ms/b, train loss: 0.000\n","total time 4.700334787368774\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 457, eval time:  0.70s, f1: 0.447, precision: 0.559, recall: 0.373\n","total time 11.799846172332764\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 458, eval time:  0.70s, f1: 0.447, precision: 0.559, recall: 0.373\n","epoch: 459, step: 17100, speed: 166.91ms/b, train loss: 0.000\n","total time 8.841090202331543\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 459, eval time:  0.71s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 2.7333145141601562\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  27, gold_num:  51\n","epoch 460, eval time:  0.79s, f1: 0.462, precision: 0.667, recall: 0.353\n","total time 5.9754884243011475\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  35, gold_num:  51\n","epoch 461, eval time:  0.72s, f1: 0.419, precision: 0.514, recall: 0.353\n","total time 0.7087383270263672\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  36, gold_num:  51\n","epoch 462, eval time:  0.72s, f1: 0.414, precision: 0.500, recall: 0.353\n","epoch: 463, step: 17200, speed: 205.40ms/b, train loss: 0.000\n","total time 3.900925874710083\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  37, gold_num:  51\n","epoch 463, eval time:  0.84s, f1: 0.409, precision: 0.486, recall: 0.353\n","total time 1.2451140880584717\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  37, gold_num:  51\n","epoch 464, eval time:  0.72s, f1: 0.409, precision: 0.486, recall: 0.353\n","total time 3.167179822921753\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  40, gold_num:  51\n","epoch 465, eval time:  0.70s, f1: 0.418, precision: 0.475, recall: 0.373\n","total time 2.701115131378174\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  25, gold_num:  51\n","epoch 466, eval time:  0.70s, f1: 0.421, precision: 0.640, recall: 0.314\n","total time 3.2207369804382324\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  31, gold_num:  51\n","epoch 467, eval time:  0.86s, f1: 0.439, precision: 0.581, recall: 0.353\n","epoch: 468, step: 17300, speed: 216.45ms/b, train loss: 0.000\n","total time 5.357600927352905\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 468, eval time:  0.70s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 0.09336280822753906\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 469, eval time:  0.72s, f1: 0.450, precision: 0.621, recall: 0.353\n","total time 5.3710808753967285\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  38, gold_num:  51\n","epoch 470, eval time:  0.70s, f1: 0.449, precision: 0.526, recall: 0.392\n","total time 3.320233106613159\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  32, gold_num:  51\n","epoch 471, eval time:  0.70s, f1: 0.482, precision: 0.625, recall: 0.392\n","epoch: 472, step: 17400, speed: 186.06ms/b, train loss: 0.000\n","total time 3.367696523666382\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  25, gold_num:  51\n","epoch 472, eval time:  0.70s, f1: 0.447, precision: 0.680, recall: 0.333\n","total time 2.9832255840301514\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  24, gold_num:  51\n","epoch 473, eval time:  0.75s, f1: 0.427, precision: 0.667, recall: 0.314\n","total time 6.479372978210449\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  28, gold_num:  51\n","epoch 474, eval time:  0.70s, f1: 0.481, precision: 0.679, recall: 0.373\n","epoch: 475, step: 17500, speed: 178.02ms/b, train loss: 0.000\n","total time 11.998150825500488\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  29, gold_num:  51\n","epoch 475, eval time:  0.70s, f1: 0.425, precision: 0.586, recall: 0.333\n","total time 6.958420515060425\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 476, eval time:  0.70s, f1: 0.436, precision: 0.630, recall: 0.333\n","epoch: 477, step: 17600, speed: 180.96ms/b, train loss: 0.000\n","total time 7.76985764503479\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  36, gold_num:  51\n","epoch 477, eval time:  0.82s, f1: 0.437, precision: 0.528, recall: 0.373\n","total time 9.916146993637085\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  32, gold_num:  51\n","epoch 478, eval time:  0.70s, f1: 0.434, precision: 0.562, recall: 0.353\n","epoch: 479, step: 17700, speed: 182.70ms/b, train loss: 0.000\n","total time 7.039227724075317\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  32, gold_num:  51\n","epoch 479, eval time:  0.72s, f1: 0.410, precision: 0.531, recall: 0.333\n","total time 2.3823440074920654\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  34, gold_num:  51\n","epoch 480, eval time:  0.71s, f1: 0.400, precision: 0.500, recall: 0.333\n","epoch: 481, step: 17800, speed: 166.81ms/b, train loss: 0.000\n","total time 12.168929815292358\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  26, gold_num:  51\n","epoch 481, eval time:  0.70s, f1: 0.416, precision: 0.615, recall: 0.314\n","total time 0.600161075592041\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  16, predict_num:  25, gold_num:  51\n","epoch 482, eval time:  0.73s, f1: 0.421, precision: 0.640, recall: 0.314\n","total time 5.5655951499938965\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  33, gold_num:  51\n","epoch 483, eval time:  0.84s, f1: 0.429, precision: 0.545, recall: 0.353\n","total time 0.9923598766326904\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  28, gold_num:  51\n","epoch 484, eval time:  0.71s, f1: 0.430, precision: 0.607, recall: 0.333\n","epoch: 485, step: 17900, speed: 201.16ms/b, train loss: 0.000\n","total time 12.156023263931274\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  38, gold_num:  51\n","epoch 485, eval time:  0.70s, f1: 0.449, precision: 0.526, recall: 0.392\n","total time 7.005395889282227\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  34, gold_num:  51\n","epoch 486, eval time:  0.69s, f1: 0.424, precision: 0.529, recall: 0.353\n","epoch: 487, step: 18000, speed: 185.93ms/b, train loss: 0.000\n","total time 6.584121465682983\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  29, gold_num:  51\n","epoch 487, eval time:  0.72s, f1: 0.450, precision: 0.621, recall: 0.353\n","epoch: 488, step: 18100, speed: 170.06ms/b, train loss: 0.000\n","total time 9.97697401046753\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  33, gold_num:  51\n","epoch 488, eval time:  0.70s, f1: 0.429, precision: 0.545, recall: 0.353\n","total time 0.16241717338562012\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  33, gold_num:  51\n","epoch 489, eval time:  0.71s, f1: 0.429, precision: 0.545, recall: 0.353\n","total time 6.265580892562866\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  36, gold_num:  51\n","epoch 490, eval time:  0.69s, f1: 0.437, precision: 0.528, recall: 0.373\n","total time 0.3763105869293213\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  36, gold_num:  51\n","epoch 491, eval time:  0.74s, f1: 0.437, precision: 0.528, recall: 0.373\n","epoch: 492, step: 18200, speed: 191.56ms/b, train loss: 0.000\n","total time 12.126160621643066\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  20, predict_num:  30, gold_num:  51\n","epoch 492, eval time:  0.69s, f1: 0.494, precision: 0.667, recall: 0.392\n","total time 12.092569351196289\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  24, gold_num:  51\n","epoch 493, eval time:  0.71s, f1: 0.480, precision: 0.750, recall: 0.353\n","epoch: 494, step: 18300, speed: 178.24ms/b, train loss: 0.000\n","total time 9.196566820144653\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  17, predict_num:  27, gold_num:  51\n","epoch 494, eval time:  0.72s, f1: 0.436, precision: 0.630, recall: 0.333\n","epoch: 495, step: 18400, speed: 165.39ms/b, train loss: 0.000\n","total time 11.72648000717163\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  34, gold_num:  51\n","epoch 495, eval time:  0.70s, f1: 0.447, precision: 0.559, recall: 0.373\n","total time 3.7579355239868164\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  35, gold_num:  51\n","epoch 496, eval time:  0.71s, f1: 0.442, precision: 0.543, recall: 0.373\n","epoch: 497, step: 18500, speed: 181.53ms/b, train loss: 0.000\n","total time 11.682766675949097\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  18, predict_num:  30, gold_num:  51\n","epoch 497, eval time:  0.71s, f1: 0.444, precision: 0.600, recall: 0.353\n","total time 7.312451124191284\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  36, gold_num:  51\n","epoch 498, eval time:  0.81s, f1: 0.437, precision: 0.528, recall: 0.373\n","epoch: 499, step: 18600, speed: 168.16ms/b, train loss: 0.000\n","total time 8.659610033035278\n"," Testing step 27 / 28, Please Waiting!\n","OneRel_DATASET_corpus3_LR_1e-05_BS_2Max_len1500Bert_ML200DP_0.2EDP_0.1\n","\n"," correct_num:  19, predict_num:  29, gold_num:  51\n","epoch 499, eval time:  0.71s, f1: 0.475, precision: 0.655, recall: 0.373\n","finish training\n","best epoch: 343, precision: 0.792, recall: 0.373, best f1: 0.507, total time: 3475.96s\n"]}],"source":["!export TF_ENABLE_ONEDNN_OPTS=0\n","!export HF_DATASETS_OFFLINE=1\n","!export TRANSFORMERS_OFFLINE=1\n","!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128 # Adjust to manage memory fragmentation\n","!touch train.py\n","!python train.py --dataset=corpus3  --batch_size=2 --max_epoch=500 --rel_num=16 --max_len=1500"]},{"cell_type":"code","source":["!pip install transformers huggingface_hub\n"],"metadata":{"id":"sQ95WWk_QsKE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708429712957,"user_tz":0,"elapsed":6464,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"2e85cba5-5e98-4c19-d507-0c4f4b8c836a"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["1da18c09b3a94aa4bc498616841faa5b","224e403377814a4ebd59f1da226b13f8","d7d09a35954f42cb8b1e2e27b195d63c","136bc07f4c3248338c449e12af7814f6","cdfdd0c1e1b944eb93ab52d094cd2084","241140447f6544e8b17a172c647b1cc3","c61f40792162451aa16eb13c90a5dfc7","aafafb28f7b04b48bbc21ed5422d8ded","17df94686317447c919864dcd268ba45","c911e2fd60f34157859d87881867b498","eb4f016a9b194b3e98c35a905ed4a816","9e6bb87cef4240c4a35c215ad7a1a900","17df008230d74934b2f099c368351ffc","6d982c9b94bb4005a138a0c3c74ced9e","b5783a8f07654fef8613378521cc2d4e","4f4c088353e6478c9252866499a2ff79","5276ce1c83d94fc78a9a28af1ab25c5e","18532ff82f084e4cb664c5879b767872","d3c11e39bf0b4b04abc3c921e1ea7d02","ccced0984987451a94a9d5f5233fb9cf","cdc925d0194b46a2b94cad618675f6de","c11eb94d810e4d7fb9c35cd1db566afa","12b3eff735304356a2585f8481b2c357","af69365bf837436e9a0589a3ad5f0aa1","8fdcff787711486096e5223262d94323","ab0c28eb661a4b5da58fa42441311969","390bb7101352437a9e10279543cc59c8","3d2d353ffee249378aa0d2c7b58ee5bd","bee981e973a5471d8df127f7a4220e89","309646788d754802bf2c560de1ce88a6","93c2436297964543a274e7bc9e576983","58fe0ee9cca44b60b87d201342afac6b"]},"id":"PRhI47d4T3eM","executionInfo":{"status":"ok","timestamp":1708429150741,"user_tz":0,"elapsed":648,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"6fd85059-6748-4762-94e7-4a1462b6e60c"},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1da18c09b3a94aa4bc498616841faa5b"}},"metadata":{}}]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fStlR2Oh6rwI","executionInfo":{"status":"ok","timestamp":1708418859686,"user_tz":0,"elapsed":14805,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"outputId":"8bb5c765-5d6a-48f2-a386-cde648409839"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-20 08:47:26.810700: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-20 08:47:26.810780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-20 08:47:26.812106: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-20 08:47:26.819298: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-20 08:47:27.830929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12020, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n","  warnings.warn(\n","2024-02-20 08:47:32.828480: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.838374: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.838646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.839408: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.839643: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.839928: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.978933: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.979171: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.979333: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2024-02-20 08:47:32.979381: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-20 08:47:32.979549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","Initialized bert_model_dir: None\n","Using bert_model_dir: None\n","loading configuration file ./pre_trained_bert/scibert_scivocab_cased/config.json\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31116\n","}\n","\n","loading weights file ./pre_trained_bert/scibert_scivocab_cased/pytorch_model.bin\n","Some weights of the model checkpoint at ./pre_trained_bert/scibert_scivocab_cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertModel were initialized from the model checkpoint at ./pre_trained_bert/scibert_scivocab_cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel/test.py\", line 62, in <module>\n","    fw.testall(model[args.model_name], model_name)\n","  File \"/content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel/framework/framework.py\", line 260, in testall\n","    model.load_state_dict(torch.load(path))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1028, in load\n","    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1246, in _legacy_load\n","    magic_number = pickle_module.load(f, **pickle_load_args)\n","EOFError: Ran out of input\n"]}],"source":["\n","\n","!python test.py --dataset=corpus3  --batch_size=2 --rel_num=16 --max_len=1500\n"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"wQKJb1JL7MfP","executionInfo":{"status":"error","timestamp":1708429720213,"user_tz":0,"elapsed":1556,"user":{"displayName":"F Xu","userId":"09663922277527295904"}},"colab":{"base_uri":"https://localhost:8080/","height":584},"outputId":"841d77c5-0a14-4340-a21a-183a6db2507d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n","For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n","  warnings.warn(warning_message, FutureWarning)\n"]},{"output_type":"error","ename":"OSError","evalue":"Tried to clone a repository in a non-empty folder that isn't a git repository ('/content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel/./checkpoint/corpus3'). If you really want to do this, do it manually:\n cd /content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel/./checkpoint/corpus3 && git init && git remote add origin && git pull origin main\n or clone repo to a new folder and move your existing files there afterwards.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-f649d40cffe2>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_push\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"343\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-43-f649d40cffe2>\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrepo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"oneRel_202402\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrepo_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Change to private=True if you want it to be private\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrepo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"./checkpoint/corpus3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_commit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial commit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mwarning_message\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarning_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, local_dir, clone_from, repo_type, token, git_user, git_email, revision, skip_lfs_files, client)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclone_from\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_git_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mclone_from\u001b[0;34m(self, repo_url, token)\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0;31m# Check if the folder is the root of a git repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_git_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                     raise EnvironmentError(\n\u001b[0m\u001b[1;32m    698\u001b[0m                         \u001b[0;34m\"Tried to clone a repository in a non-empty folder that isn't\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                         \u001b[0;34mf\" a git repository ('{self.local_dir}'). If you really want to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Tried to clone a repository in a non-empty folder that isn't a git repository ('/content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel/./checkpoint/corpus3'). If you really want to do this, do it manually:\n cd /content/drive/MyDrive/Gdrive_PhD/20240106_oneRel_code/OneRel/./checkpoint/corpus3 && git init && git remote add origin && git pull origin main\n or clone repo to a new folder and move your existing files there afterwards."]}],"source":["import huggingface_hub\n","from huggingface_hub import Repository\n","\n","def push_to_hub(epoch):\n","    repo_name = f\"oneRel_202402\"\n","    repo_url = huggingface_hub.create_repo(repo_name, private=False)  # Change to private=True if you want it to be private\n","    repo = Repository(local_dir=f\"./checkpoint/corpus3\", clone_from=repo_url)\n","    repo.git_add()\n","    repo.git_commit(\"Initial commit\")\n","    repo.git_push()\n","\n","push_to_hub(\"343\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPNo/aAkaoCCffGUO/xmeRF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1da18c09b3a94aa4bc498616841faa5b":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_cdc925d0194b46a2b94cad618675f6de","IPY_MODEL_c11eb94d810e4d7fb9c35cd1db566afa","IPY_MODEL_12b3eff735304356a2585f8481b2c357","IPY_MODEL_af69365bf837436e9a0589a3ad5f0aa1"],"layout":"IPY_MODEL_c61f40792162451aa16eb13c90a5dfc7"}},"224e403377814a4ebd59f1da226b13f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aafafb28f7b04b48bbc21ed5422d8ded","placeholder":"","style":"IPY_MODEL_17df94686317447c919864dcd268ba45","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"d7d09a35954f42cb8b1e2e27b195d63c":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_c911e2fd60f34157859d87881867b498","placeholder":"","style":"IPY_MODEL_eb4f016a9b194b3e98c35a905ed4a816","value":""}},"136bc07f4c3248338c449e12af7814f6":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_9e6bb87cef4240c4a35c215ad7a1a900","style":"IPY_MODEL_17df008230d74934b2f099c368351ffc","value":true}},"cdfdd0c1e1b944eb93ab52d094cd2084":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_6d982c9b94bb4005a138a0c3c74ced9e","style":"IPY_MODEL_b5783a8f07654fef8613378521cc2d4e","tooltip":""}},"241140447f6544e8b17a172c647b1cc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f4c088353e6478c9252866499a2ff79","placeholder":"","style":"IPY_MODEL_5276ce1c83d94fc78a9a28af1ab25c5e","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"c61f40792162451aa16eb13c90a5dfc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"aafafb28f7b04b48bbc21ed5422d8ded":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17df94686317447c919864dcd268ba45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c911e2fd60f34157859d87881867b498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb4f016a9b194b3e98c35a905ed4a816":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e6bb87cef4240c4a35c215ad7a1a900":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17df008230d74934b2f099c368351ffc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d982c9b94bb4005a138a0c3c74ced9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5783a8f07654fef8613378521cc2d4e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"4f4c088353e6478c9252866499a2ff79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5276ce1c83d94fc78a9a28af1ab25c5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18532ff82f084e4cb664c5879b767872":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3c11e39bf0b4b04abc3c921e1ea7d02","placeholder":"","style":"IPY_MODEL_ccced0984987451a94a9d5f5233fb9cf","value":"Connecting..."}},"d3c11e39bf0b4b04abc3c921e1ea7d02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccced0984987451a94a9d5f5233fb9cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdc925d0194b46a2b94cad618675f6de":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fdcff787711486096e5223262d94323","placeholder":"","style":"IPY_MODEL_ab0c28eb661a4b5da58fa42441311969","value":"Token is valid (permission: write)."}},"c11eb94d810e4d7fb9c35cd1db566afa":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_390bb7101352437a9e10279543cc59c8","placeholder":"","style":"IPY_MODEL_3d2d353ffee249378aa0d2c7b58ee5bd","value":"Your token has been saved in your configured git credential helpers (store)."}},"12b3eff735304356a2585f8481b2c357":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bee981e973a5471d8df127f7a4220e89","placeholder":"","style":"IPY_MODEL_309646788d754802bf2c560de1ce88a6","value":"Your token has been saved to /root/.cache/huggingface/token"}},"af69365bf837436e9a0589a3ad5f0aa1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93c2436297964543a274e7bc9e576983","placeholder":"","style":"IPY_MODEL_58fe0ee9cca44b60b87d201342afac6b","value":"Login successful"}},"8fdcff787711486096e5223262d94323":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab0c28eb661a4b5da58fa42441311969":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"390bb7101352437a9e10279543cc59c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d2d353ffee249378aa0d2c7b58ee5bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bee981e973a5471d8df127f7a4220e89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"309646788d754802bf2c560de1ce88a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93c2436297964543a274e7bc9e576983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58fe0ee9cca44b60b87d201342afac6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}